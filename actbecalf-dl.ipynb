{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AcTBeCalf - Testing the Dataset\n",
    "\n",
    "---\n",
    "\n",
    "**Group:**\n",
    "- João Gabriel\n",
    "- Gustavo Tironi\n",
    "\n",
    "**Subject:**\n",
    "- Deep Learning - Dário Oliveira\n",
    "\n",
    "---\n",
    "\n",
    "### Objective\n",
    "\n",
    "Using the AcTBeCalf dataset, with more than 27 hours of labelled data and 2 weeks of unlabelled data from sensors on calves, we want to analyse different models and get the best model possible to predict calf behaviour using only these sensors, trying to beat the simple models they've tried before (only using 2 or 4 classes).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-01T20:08:55.624804Z",
     "iopub.status.busy": "2025-12-01T20:08:55.624364Z",
     "iopub.status.idle": "2025-12-01T20:08:55.636266Z",
     "shell.execute_reply": "2025-12-01T20:08:55.635480Z",
     "shell.execute_reply.started": "2025-12-01T20:08:55.624732Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px  # For interactive graphics\n",
    "import random\n",
    "import os\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Setup done. Using: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurations\n",
    "\n",
    "---\n",
    "\n",
    "All the parameters we'll use during training and testing, also with paths and dataset information (such as FREQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T20:08:55.637590Z",
     "iopub.status.busy": "2025-12-01T20:08:55.637361Z",
     "iopub.status.idle": "2025-12-01T20:08:55.650154Z",
     "shell.execute_reply": "2025-12-01T20:08:55.649434Z",
     "shell.execute_reply.started": "2025-12-01T20:08:55.637566Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    LABELED_PATH = '/kaggle/input/calf-dl/AcTBeCalf.parquet'\n",
    "    UNLABELED_PATH = '/kaggle/input/calf-dl/Time_Adj_Raw_Data.parquet'\n",
    "    \n",
    "    # Parameters\n",
    "    FREQ = 25  # Hz\n",
    "    WINDOW_SECONDS = 3\n",
    "    WINDOW_SIZE = FREQ * WINDOW_SECONDS # 250 samples\n",
    "    CHANNELS = 3 # X, Y, Z\n",
    "    \n",
    "    # Train\n",
    "    BATCH_SIZE = 64\n",
    "    NUM_WORKERS = 2 # Using 2, with more than this it may struggle\n",
    "\n",
    "print(\"Config done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Inspection\n",
    "\n",
    "---\n",
    "\n",
    "Looking at all the info from the dataset, passing through and catching any mistakes that the new parquet might have before we start using the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T20:08:55.651728Z",
     "iopub.status.busy": "2025-12-01T20:08:55.651480Z",
     "iopub.status.idle": "2025-12-01T20:08:59.169942Z",
     "shell.execute_reply": "2025-12-01T20:08:59.169065Z",
     "shell.execute_reply.started": "2025-12-01T20:08:55.651711Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"INSPECTING LABELED DATASET (AcTBeCalf)\")\n",
    "\n",
    "try:\n",
    "    df_labeled = pd.read_parquet(Config.LABELED_PATH)\n",
    "    \n",
    "    # Basic Info\n",
    "    print(f\"Shape: {df_labeled.shape}\")\n",
    "    print(\"Columns:\", df_labeled.columns.tolist())\n",
    "    print(\"\\nData Types:\")\n",
    "    print(df_labeled.dtypes)\n",
    "    \n",
    "    # Null Check\n",
    "    print(\"\\nMissing Values  per column:\")\n",
    "    null_counts = df_labeled.isnull().sum()\n",
    "    print(null_counts[null_counts > 0])\n",
    "    print(\"\\ncalfId Column:\")\n",
    "    unique_calves = df_labeled['calfId'].unique()\n",
    "    print(f\"Number of unique calves: {len(unique_calves)}\")\n",
    "    print(f\"First 10 unique values: {unique_calves[:10]}\")\n",
    "    \n",
    "    if df_labeled['calfId'].isnull().all():\n",
    "        print(\"'calfId' column is NaN. Subject-based split is impossible.\")\n",
    "    \n",
    "    print(\"\\nbehaviour Column:\")\n",
    "    raw_labels = df_labeled['behaviour'].astype(str).unique()\n",
    "    print(f\"Total unique raw labels: {len(raw_labels)}\")\n",
    "    print(\"Sample of labels (First 20):\")\n",
    "    print(raw_labels[:530])\n",
    "    \n",
    "    print(\"\\nLabel Counts (Top 10 most frequent):\")\n",
    "    print(df_labeled['behaviour'].astype(str).value_counts().head(10))\n",
    "    \n",
    "    print(\"\\nLabel Counts (Top 10 LEAST frequent - Potential split errors):\")\n",
    "    print(df_labeled['behaviour'].astype(str).value_counts().tail(10))\n",
    "\n",
    "    # 5. Analyze 'segId'\n",
    "    print(\"\\nsegId Column:\")\n",
    "    n_segments = df_labeled['segId'].nunique()\n",
    "    print(f\"Total unique segments: {n_segments}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error inspecting labeled data: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "try:\n",
    "    df_unlabeled_head = pl.scan_parquet(Config.UNLABELED_PATH).fetch(5)\n",
    "    \n",
    "    print(\"Unlabeled Data Schema:\")\n",
    "    print(df_unlabeled_head.schema)\n",
    "    \n",
    "    print(\"\\nFirst 5 rows:\")\n",
    "    print(df_unlabeled_head)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error inspecting unlabeled data: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preparation\n",
    "### For TimeMAE and ResNet1D Experiments\n",
    "\n",
    "Here we define the PyTorch Datasets for both labeled and unlabeled data. The goal is to prepare data in a **windowed format** suitable for 1D CNNs or masked autoencoders. It's a bit different than the method we'll use later.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Labeled Dataset: `LabeledCalfDataset`**\n",
    "\n",
    "1. **Purpose:** Create windows of signals with overlapping segments from labeled calf accelerometer data.\n",
    "2. **Key Steps:**\n",
    "   - Loads a Parquet file with labeled behavioral data.\n",
    "   - Maps **string labels to integer codes** for training consistency.\n",
    "   - Uses **segId** to avoid splitting continuous behavioral segments.\n",
    "   - Creates **sliding windows** of size `window_size` (250 samples = 10s at 25 Hz) with **50% overlap** for data augmentation.\n",
    "   - Overlap increases dataset size while preserving temporal coherence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T20:08:59.171071Z",
     "iopub.status.busy": "2025-12-01T20:08:59.170757Z",
     "iopub.status.idle": "2025-12-01T20:08:59.228931Z",
     "shell.execute_reply": "2025-12-01T20:08:59.228164Z",
     "shell.execute_reply.started": "2025-12-01T20:08:59.171052Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class LabeledCalfDataset(Dataset):\n",
    "    def __init__(self, parquet_path, window_size=250):\n",
    "        print(f\"Loading Labeled Dataset: {parquet_path}...\")\n",
    "        self.data = pd.read_parquet(parquet_path)\n",
    "        \n",
    "        # Map labels to integers for consistent ordering\n",
    "        cats = sorted(self.data['behaviour'].unique())\n",
    "        self.label_map = {label: i for i, label in enumerate(cats)}\n",
    "        self.int_to_label = {i: label for label, i in self.label_map.items()}\n",
    "        \n",
    "        self.indices = []\n",
    "        \n",
    "        # Group by segId to avoid breaking windows\n",
    "        for seg_id, group in self.data.groupby('segId'):\n",
    "            n = len(group)\n",
    "            if n >= window_size:\n",
    "                start_global = group.index[0]\n",
    "                # Stride = window_size // 2 (50% overlap for natural data augmentation)\n",
    "                for i in range(0, n - window_size + 1, window_size // 2):\n",
    "                    self.indices.append((start_global + i, start_global + i + window_size))\n",
    "        \n",
    "        self.signals = self.data[['accX', 'accY', 'accZ']].values.astype('float32')\n",
    "        \n",
    "        # Map string labels to integer codes\n",
    "        self.labels = self.data['behaviour'].map(self.label_map).values.astype('int64')\n",
    "        print(f\"Labeled Dataset Ready: {len(self.indices)} samples, {len(cats)} classes.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        s, e = self.indices[idx]\n",
    "        x = self.signals[s:e]\n",
    "        y = self.labels[s]\n",
    "        # Transpose (Time, Channel) -> (Channel, Time) for PyTorch\n",
    "        return torch.tensor(x).permute(1, 0), torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "\n",
    "class UnlabeledCalfDataset(Dataset):\n",
    "    def __init__(self, parquet_path, window_size=250):\n",
    "        print(f\"Loading Unlabeled Dataset: {parquet_path}...\")\n",
    "        # Use Polars for memory efficiency\n",
    "        df = pl.read_parquet(parquet_path)\n",
    "        \n",
    "        self.signals = df.select(['accX', 'accY', 'accZ']).to_numpy().astype('float32')\n",
    "        timestamps = df.select('dateTime').to_numpy().flatten()  # array of int64 (ns) or datetime\n",
    "        \n",
    "        self.valid_indices = []\n",
    "        total = len(df)\n",
    "        stride = window_size  # No overlap for speed\n",
    "        \n",
    "        # Simplified gap detection logic\n",
    "        limit_ns = window_size * 40 * 1_000_000 * 1.1\n",
    "        print(\"Calculating valid indices (ignoring gaps)...\")\n",
    "        # Vectorized approach: check temporal consistency\n",
    "        times = timestamps[::stride]  # pick start times\n",
    "        \n",
    "        # Simplified implementation: assume continuous data except for large gaps\n",
    "        for i in range(0, total - window_size, stride):\n",
    "             self.valid_indices.append(i)\n",
    "             \n",
    "        print(f\"Unlabeled Dataset Ready: {len(self.valid_indices)} samples.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.valid_indices)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        s = self.valid_indices[idx]\n",
    "        x = self.signals[s : s + Config.WINDOW_SIZE]\n",
    "        return torch.tensor(x).permute(1, 0), torch.tensor(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T20:08:59.230606Z",
     "iopub.status.busy": "2025-12-01T20:08:59.230404Z",
     "iopub.status.idle": "2025-12-01T20:09:06.590698Z",
     "shell.execute_reply": "2025-12-01T20:09:06.590007Z",
     "shell.execute_reply.started": "2025-12-01T20:08:59.230590Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Dataset instantiation\n",
    "ds_labeled = LabeledCalfDataset(Config.LABELED_PATH, Config.WINDOW_SIZE)\n",
    "ds_unlabeled = UnlabeledCalfDataset(Config.UNLABELED_PATH, Config.WINDOW_SIZE)\n",
    "\n",
    "# Quick check of the first sample\n",
    "x, y = ds_labeled[0]\n",
    "print(f\"\\nTensor overview:\")\n",
    "print(f\"Input Shape (C, L): {x.shape} (Expected: 3, {Config.WINDOW_SIZE})\")\n",
    "print(f\"Label: {y} ('{ds_labeled.int_to_label[y.item()]}')\")\n",
    "print(f\"Data type: {x.dtype}\")\n",
    "\n",
    "# DataLoader setup\n",
    "dl_check = DataLoader(ds_labeled, batch_size=32, shuffle=True)\n",
    "batch_x, batch_y = next(iter(dl_check))\n",
    "print(f\"Batch Shape: {batch_x.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T20:09:06.591880Z",
     "iopub.status.busy": "2025-12-01T20:09:06.591626Z",
     "iopub.status.idle": "2025-12-01T20:09:07.430077Z",
     "shell.execute_reply": "2025-12-01T20:09:07.429329Z",
     "shell.execute_reply.started": "2025-12-01T20:09:06.591854Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Quick count using the Dataset's internal DataFrame\n",
    "df_counts = ds_labeled.data['behaviour'].value_counts().reset_index()\n",
    "df_counts.columns = ['behaviour', 'count']\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.barplot(data=df_counts, x='count', y='behaviour', palette='viridis')\n",
    "plt.title(\"Behavior Distribution (Labeled Set)\")\n",
    "plt.xlabel(\"Number of Samples (Raw Rows)\")\n",
    "plt.xscale('log')  # Log scale helps visualize rare classes\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"There are rare classes (Vocalization, Grooming|None) and very common classes.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Sample Accelerometer Windows\n",
    "\n",
    "This function plots a **3-axis accelerometer signal** for a specific behavior class from the labeled dataset. It will help us see if the labels make sense, like a lying calf to not be moving much, and a running calf the opposite.\n",
    "\n",
    "- **Behavior:**\n",
    "  - If `index` is not provided, randomly selects a window corresponding to the requested label.\n",
    "  - Converts the `(channels, time)` tensor to a DataFrame with axes labeled:\n",
    "    - `X (Up/Down)`\n",
    "    - `Y (Forward/Backward)`\n",
    "    - `Z (Left/Right)`\n",
    "  - Time axis is computed in seconds using the configured sampling frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T20:09:07.431220Z",
     "iopub.status.busy": "2025-12-01T20:09:07.430897Z",
     "iopub.status.idle": "2025-12-01T20:09:07.571677Z",
     "shell.execute_reply": "2025-12-01T20:09:07.570901Z",
     "shell.execute_reply.started": "2025-12-01T20:09:07.431196Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_signal(dataset, label_name=None, index=None):\n",
    "    \"\"\"Plots the 3-axis accelerometer signal from a random window of a specific class.\"\"\"\n",
    "    \n",
    "    # If no explicit index is given, sample a window belonging to the requested class\n",
    "    if index is None:\n",
    "        target_int = dataset.label_map[label_name]\n",
    "        candidates = [i for i, idxs in enumerate(dataset.indices) \n",
    "                      if dataset.labels[idxs[0]] == target_int]\n",
    "        if not candidates:\n",
    "            return print(f\"No data available for {label_name}\")\n",
    "        idx = random.choice(candidates)\n",
    "    else:\n",
    "        idx = index\n",
    "\n",
    "    # Retrieve the tensor window and its label\n",
    "    x_tensor, y_tensor = dataset[idx]\n",
    "    label_str = dataset.int_to_label[y_tensor.item()]\n",
    "    \n",
    "    # Convert the tensor (channels-first) to a DataFrame for plotting\n",
    "    data_np = x_tensor.permute(1, 0).numpy()\n",
    "    df_plot = pd.DataFrame(\n",
    "        data_np, \n",
    "        columns=['X (Up/Down)', 'Y (Forward/Backward)', 'Z (Left/Right)']\n",
    "    )\n",
    "    df_plot['Time'] = np.arange(len(df_plot)) / Config.FREQ\n",
    "    \n",
    "    # Create interactive plot\n",
    "    fig = px.line(\n",
    "        df_plot,\n",
    "        x='Time',\n",
    "        y=['X (Up/Down)', 'Y (Forward/Backward)', 'Z (Left/Right)'],\n",
    "        title=f\"Sample of Behavior: {label_str.upper()} (Index {idx})\"\n",
    "    )\n",
    "    fig.update_layout(yaxis_title=\"Acceleration (g)\", xaxis_title=\"Seconds\")\n",
    "    fig.show()\n",
    "\n",
    "plot_signal(ds_labeled, label_name='lying')    # Should appear nearly flat\n",
    "plot_signal(ds_labeled, label_name='running')  # Should show peaks and valleys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T20:09:07.572829Z",
     "iopub.status.busy": "2025-12-01T20:09:07.572548Z",
     "iopub.status.idle": "2025-12-01T20:09:07.621868Z",
     "shell.execute_reply": "2025-12-01T20:09:07.621171Z",
     "shell.execute_reply.started": "2025-12-01T20:09:07.572802Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Random sample to analyse\n",
    "idx_rnd = random.randint(0, len(ds_unlabeled)-1)\n",
    "x_u, _ = ds_unlabeled[idx_rnd]\n",
    "\n",
    "data_np = x_u.permute(1, 0).numpy()\n",
    "df_u = pd.DataFrame(data_np, columns=['X', 'Y', 'Z'])\n",
    "df_u['Time'] = np.arange(len(df_u)) / Config.FREQ\n",
    "\n",
    "fig = px.line(df_u, x='Time', y=['X', 'Y', 'Z'], \n",
    "              title=f\"Unlabeled sample (Index {idx_rnd})\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Behavior Taxonomy Mapping and Dataset Splitting\n",
    "\n",
    "---\n",
    "\n",
    "#### 1. Behavior Mapping to Super-Classes\n",
    "\n",
    "The original dataset contains many fine-grained behaviors, some of which are rare or short-lived. To make the learning task feasible and reduce class imbalance, we map all behaviors into 19 super-classes, which are also specified:\n",
    "\n",
    "- **Rare Events:** e.g., cough, fall, vocalization → `'rare_event'`\n",
    "- **Abnormal:** e.g., cross-suckle, tongue, abnormal movements → `'abnormal'`\n",
    "- **Self-Reactive (SRS):** scratch, rub, stretch → `'srs'`\n",
    "- **Elimination:** defecation or urination → `'elimination'`\n",
    "- **Play Behaviors:** jump, headbutt, mount, object play → `'play'`\n",
    "- **Social Interaction:** nudge, social sniff → `'social_interaction'`\n",
    "- **Rumination:** `'rumination'`\n",
    "- **Drinking:** `'drinking'`\n",
    "- **Eating:** `'eating'`\n",
    "- **Exploration:** sniffing (non-social) → `'sniff'`\n",
    "- **Oral Manipulation:** `'oral_manipulation'`\n",
    "- **Grooming:** self-grooming → `'grooming'`\n",
    "- **Transitions:** rising, lying down → `'rising'`, `'lying_down_action'`\n",
    "- **Locomotion:** run → `'running'`, walk/backward → `'walking'`\n",
    "- **Base Postures:** lying → `'lying'`, standing → `'standing'`\n",
    "\n",
    "This ensures that we have enough samples per class while maintaining semantic meaning. Rare or minor behaviors are grouped to avoid extremely sparse classes that are difficult for models to learn.\n",
    "\n",
    "---\n",
    "#### Train/Validation/Test Split\n",
    "\n",
    "To ensure **subject-independent evaluation**, we split the dataset based on **`calfId`** whenever possible:\n",
    "\n",
    "- **Train set:** 70% of calves\n",
    "- **Validation set:** 15% of calves\n",
    "- **Test set:** 15% of calves\n",
    "\n",
    "If there are very few calves, we fallback to splitting by `segId`, and this guarantees that the same calf does not appear in both training and testing, which prevents overfitting to individual animals patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T20:09:07.623119Z",
     "iopub.status.busy": "2025-12-01T20:09:07.622745Z",
     "iopub.status.idle": "2025-12-01T20:09:08.297398Z",
     "shell.execute_reply": "2025-12-01T20:09:08.296510Z",
     "shell.execute_reply.started": "2025-12-01T20:09:07.623089Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_full = pd.read_parquet(Config.LABELED_PATH)\n",
    "\n",
    "def map_behavior(label):\n",
    "    # Convert to lowercase and string to avoid parsing issues\n",
    "    label = str(label).lower().strip()\n",
    "    \n",
    "    # 1. RARE EVENTS (Highest priority because they are short and uncommon)\n",
    "    if any(x in label for x in ['cough', 'fall', 'vocalisation']):\n",
    "        return 'rare_event'\n",
    "        \n",
    "    # 2. ABNORMAL BEHAVIORS\n",
    "    if any(x in label for x in ['cross-suckle', 'tongue', 'abnormal']):\n",
    "        return 'abnormal'\n",
    "        \n",
    "    # 3. SRS (Self-Reactive: scratch, rub, stretch)\n",
    "    if any(x in label for x in ['scratch', 'rub', 'stretch', 'srs']):\n",
    "        return 'srs'\n",
    "        \n",
    "    # 4. ELIMINATION\n",
    "    if 'defecat' in label or 'urinat' in label:\n",
    "        return 'elimination'\n",
    "        \n",
    "    # 5. PLAY BEHAVIORS — High-energy activities\n",
    "    # Includes jump, headbutt, mount, playing with objects\n",
    "    if any(x in label for x in ['play', 'jump', 'headbutt', 'mount']):\n",
    "        return 'play'\n",
    "        \n",
    "    # 6. SOCIAL INTERACTION\n",
    "    # The paper groups \"nudge\" and \"social sniff\" here.\n",
    "    if 'social' in label or 'nudge' in label:\n",
    "        return 'social_interaction'\n",
    "        \n",
    "    # 7. RUMINATION\n",
    "    if 'ruminat' in label:\n",
    "        return 'rumination'\n",
    "        \n",
    "    # 8. DRINKING\n",
    "    if 'drink' in label:\n",
    "        return 'drinking'\n",
    "        \n",
    "    # 9. EATING\n",
    "    if 'eat' in label:\n",
    "        return 'eating'\n",
    "        \n",
    "    # 10. EXPLORATION (Non-social sniffing)\n",
    "    if 'sniff' in label:\n",
    "        return 'sniff'\n",
    "        \n",
    "    # 11. ORAL MANIPULATION\n",
    "    if 'oral' in label or 'manipulation' in label:\n",
    "        return 'oral_manipulation'\n",
    "        \n",
    "    # 12. GROOMING (Self-grooming)\n",
    "    # \"social_groom\" would have been caught earlier under social interaction.\n",
    "    if 'groom' in label:\n",
    "        return 'grooming'\n",
    "        \n",
    "    # 13. TRANSITIONS (Checked before static postures)\n",
    "    if 'rising' in label:\n",
    "        return 'rising'\n",
    "    if 'lying down' in label or 'lying-down' in label:\n",
    "        return 'lying_down_action'\n",
    "        \n",
    "    # 14. LOCOMOTION\n",
    "    if 'run' in label:\n",
    "        return 'running'\n",
    "    if 'walk' in label or 'backward' in label:\n",
    "        return 'walking'\n",
    "        \n",
    "    # 15. BASE POSTURES (Fallback)\n",
    "    if 'ly' in label:  # captures \"lying\"\n",
    "        return 'lying'\n",
    "    if 'stand' in label:\n",
    "        return 'standing'\n",
    "        \n",
    "    return 'other'\n",
    "\n",
    "# Apply taxonomy mapping based on the behavioral paper\n",
    "print(\"Applying behavior taxonomy...\")\n",
    "df_full['behaviour_clean'] = df_full['behaviour'].apply(map_behavior).astype('category')\n",
    "\n",
    "# Display resulting classes\n",
    "classes = sorted(df_full['behaviour_clean'].unique())\n",
    "print(f\"Mapped Classes ({len(classes)}):\")\n",
    "for c in classes:\n",
    "    print(f\"  - {c}\")\n",
    "\n",
    "# Replace categorical labels with integer indices\n",
    "label_map = {c: i for i, c in enumerate(classes)}\n",
    "int_to_label = {i: c for c, i in label_map.items()}\n",
    "df_full['label_code'] = df_full['behaviour_clean'].map(label_map).astype(int)\n",
    "\n",
    "# --- SUBJECT-INDEPENDENT TRAINING SPLIT ---\n",
    "unique_calves = df_full['calfId'].unique()\n",
    "\n",
    "if len(unique_calves) > 5:\n",
    "    print(\"\\nSplitting by subject (calfId)\")\n",
    "    train_ids, temp_ids = train_test_split(unique_calves, test_size=0.30, random_state=42)\n",
    "    val_ids, test_ids = train_test_split(temp_ids, test_size=0.50, random_state=42)\n",
    "    col_split = 'calfId'\n",
    "    \n",
    "    train_df = df_full[df_full['calfId'].isin(train_ids)].reset_index(drop=True)\n",
    "    val_df = df_full[df_full['calfId'].isin(val_ids)].reset_index(drop=True)\n",
    "    test_df = df_full[df_full['calfId'].isin(test_ids)].reset_index(drop=True)\n",
    "\n",
    "else:\n",
    "    print(\"\\nSplitting by segment (few calf IDs available)\")\n",
    "    # Safe fallback in case calfId is unreliable\n",
    "    seg_ids = df_full['segId'].unique()\n",
    "    train_ids, temp_ids = train_test_split(seg_ids, test_size=0.30, random_state=42)\n",
    "    val_ids, test_ids = train_test_split(temp_ids, test_size=0.50, random_state=42)\n",
    "    \n",
    "    train_df = df_full[df_full['segId'].isin(train_ids)].reset_index(drop=True)\n",
    "    val_df = df_full[df_full['segId'].isin(val_ids)].reset_index(drop=True)\n",
    "    test_df = df_full[df_full['segId'].isin(test_ids)].reset_index(drop=True)\n",
    "\n",
    "# Compute class weights for handling imbalance\n",
    "count_series = train_df['label_code'].value_counts().sort_index()\n",
    "counts = np.zeros(len(classes))\n",
    "for idx, val in count_series.items():\n",
    "    if idx < len(counts):\n",
    "        counts[idx] = val\n",
    "\n",
    "weights = len(train_df) / (len(classes) * (counts + 1))\n",
    "class_weights = torch.tensor(weights, dtype=torch.float).to(device)\n",
    "\n",
    "print(f\"\\nFinal Dataset Sizes:\")\n",
    "print(f\"Train: {len(train_df)} | Val: {len(val_df)} | Test: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sensor Preprocessing\n",
    "\n",
    "This class handles **normalization and feature augmentation** for accelerometer data:\n",
    "\n",
    "1. **Fit:** Computes the global **mean and standard deviation** for the X, Y, Z channels using only the training set.\n",
    "\n",
    "2. **Transform:**  \n",
    "   - Normalizes the 3-axis accelerometer signals using Z-score.  \n",
    "   - Computes a **fourth channel: the magnitude** of the acceleration vector (`sqrt(X² + Y² + Z²)`).  \n",
    "   - Returns a 4-channel array `[X_norm, Y_norm, Z_norm, Magnitude]` ready for model input.\n",
    "\n",
    "This ensures consistent scaling and adds a useful summary feature for motion intensity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T20:09:08.300293Z",
     "iopub.status.busy": "2025-12-01T20:09:08.299980Z",
     "iopub.status.idle": "2025-12-01T20:09:08.306759Z",
     "shell.execute_reply": "2025-12-01T20:09:08.306044Z",
     "shell.execute_reply.started": "2025-12-01T20:09:08.300274Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SensorPreprocessor:\n",
    "    def __init__(self):\n",
    "        self.mean = None\n",
    "        self.std = None\n",
    "        \n",
    "    def fit(self, dataframe):\n",
    "        \"\"\" Calculate statistics only on the training set \"\"\"\n",
    "        print(\"Calculating global statistics (X, Y, Z)...\")\n",
    "        signals = dataframe[['accX', 'accY', 'accZ']].values\n",
    "        self.mean = np.mean(signals, axis=0)\n",
    "        self.std = np.std(signals, axis=0)\n",
    "        # Safety against division by zero\n",
    "        self.std[self.std == 0] = 1.0\n",
    "        print(f\"   Mean: {self.mean} | Std: {self.std}\")\n",
    "        \n",
    "    def transform(self, dataframe):\n",
    "        \"\"\" Normalize and create the 4th channel (Magnitude) \"\"\"\n",
    "        x = dataframe[['accX', 'accY', 'accZ']].values.astype(np.float32)\n",
    "        x_norm = (x - self.mean) / self.std\n",
    "        mag = np.sqrt(np.sum(x_norm**2, axis=1, keepdims=True))\n",
    "        x_final = np.concatenate([x_norm, mag], axis=1)\n",
    "        return x_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-Memory Windowed Dataset\n",
    "\n",
    "This dataset class prepares the **windowed input for PyTorch models**:\n",
    "\n",
    "- **Preprocessing:** Applies the `SensorPreprocessor` to normalize signals and add the magnitude channel.  \n",
    "- **Sliding windows:** Creates overlapping windows per segment to avoid mixing behaviors or calves.  \n",
    "  - Training uses 50% overlap (`stride = window_size // 2`) for data augmentation.  \n",
    "  - Validation/test use non-overlapping windows.  \n",
    "- **Output format:** `(Channels, Time)` tensors `(4, window_size)` along with the corresponding label.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T20:09:08.308436Z",
     "iopub.status.busy": "2025-12-01T20:09:08.308232Z",
     "iopub.status.idle": "2025-12-01T20:09:08.322434Z",
     "shell.execute_reply": "2025-12-01T20:09:08.321752Z",
     "shell.execute_reply.started": "2025-12-01T20:09:08.308419Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class InMemoryCalfDataset(Dataset):\n",
    "    def __init__(self, dataframe, window_size=75, stride=None, mode='train', preprocessor=None):\n",
    "        self.window_size = window_size\n",
    "        self.indices = []\n",
    "        \n",
    "        print(f\"Processing Dataset ({mode})...\")\n",
    "        \n",
    "        # Apply preprocessing immediately (saves CPU during training)\n",
    "        if preprocessor:\n",
    "            self.signals = preprocessor.transform(dataframe)  # Returns array (N_samples, 4)\n",
    "        else:\n",
    "            raise ValueError(\"A trained preprocessor must be provided!\")\n",
    "\n",
    "        # Labels and segment IDs\n",
    "        self.labels = dataframe['label_code'].values.astype('int64')\n",
    "        self.seg_ids = dataframe['segId'].values\n",
    "\n",
    "        # Create sliding windows\n",
    "        if stride is None:\n",
    "            stride = window_size // 2 if mode == 'train' else window_size\n",
    "        \n",
    "        # Find segment boundaries to avoid mixing calves/behaviors\n",
    "        changes = np.where(self.seg_ids[:-1] != self.seg_ids[1:])[0] + 1\n",
    "        starts = np.concatenate(([0], changes))\n",
    "        ends = np.concatenate((changes, [len(self.signals)]))\n",
    "        \n",
    "        for start, end in zip(starts, ends):\n",
    "            n = end - start\n",
    "            if n >= window_size:\n",
    "                for i in range(start, end - window_size + 1, stride):\n",
    "                    self.indices.append(i)\n",
    "\n",
    "        print(f\"{len(self.indices)} windows created.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        start = self.indices[idx]\n",
    "        end = start + self.window_size\n",
    "        \n",
    "        # Slice from preprocessed array\n",
    "        x = self.signals[start:end]  # (window_size, 4)\n",
    "        y = self.labels[start]       # Label at start of the window\n",
    "        \n",
    "        # PyTorch expects (Channels, Time) -> permute to (4, window_size)\n",
    "        return torch.tensor(x).permute(1, 0), torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "\n",
    "# Instantiate datasets\n",
    "ds_train = InMemoryCalfDataset(train_df, Config.WINDOW_SIZE, mode='train')\n",
    "ds_val   = InMemoryCalfDataset(val_df, Config.WINDOW_SIZE, mode='val')\n",
    "ds_test  = InMemoryCalfDataset(test_df, Config.WINDOW_SIZE, mode='test')\n",
    "\n",
    "# DataLoaders\n",
    "dl_train = DataLoader(ds_train, batch_size=Config.BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
    "dl_val   = DataLoader(ds_val, batch_size=Config.BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "dl_test  = DataLoader(ds_test, batch_size=Config.BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "print(f\"\\nBatches per Epoch: {len(dl_train)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline\n",
    "\n",
    "---\n",
    "\n",
    "Here we have the simple ResNetBaseline, which is a modified CNN1D, who we'll be using to compare the TimeMAE, which will be our main model for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T20:09:08.323242Z",
     "iopub.status.busy": "2025-12-01T20:09:08.323021Z",
     "iopub.status.idle": "2025-12-01T20:09:08.340036Z",
     "shell.execute_reply": "2025-12-01T20:09:08.339427Z",
     "shell.execute_reply.started": "2025-12-01T20:09:08.323209Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "class ResNetBaseline(nn.Module):\n",
    "    def __init__(self, num_classes, in_channels=4):\n",
    "        super().__init__()\n",
    "        self.backbone = models.resnet18(weights=None)\n",
    "        self.backbone.conv1 = nn.Conv2d(\n",
    "            in_channels, 64, kernel_size=7, stride=2, padding=3, bias=False\n",
    "        )\n",
    "        n_features = self.backbone.fc.in_features\n",
    "        self.backbone.fc = nn.Linear(n_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(2) # (Batch, 4, 1, 75)\n",
    "        x = self.backbone(x)\n",
    "        return x\n",
    "\n",
    "# Initialize Model\n",
    "model = ResNetBaseline(num_classes=len(classes)).to(device)\n",
    "print(f\"Model created for {len(classes)} classes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop for ResNet1D / TimeMAE Baseline\n",
    " \n",
    "- **Training Loop:**\n",
    "  - Iterate over epochs.\n",
    "  - Training phase: forward pass, compute loss, backprop, update weights.\n",
    "  - Validation phase: evaluate without gradients.\n",
    "  - Track average loss and accuracy for both train and validation.\n",
    "\n",
    "**Results:**  \n",
    "- Train Accuracy: ~77%  \n",
    "- Validation Accuracy: ~59%  \n",
    "\n",
    "This confirms the baseline is worse than Random Forest or LSTM+CNN models, showing the challenge of this 19-class problem for simple architectures. This model was trained more than once, with others learning rates and hiperparameters, but it didn't get better than 60% in any of the tests.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T20:09:08.341129Z",
     "iopub.status.busy": "2025-12-01T20:09:08.340860Z",
     "iopub.status.idle": "2025-12-01T20:09:08.357332Z",
     "shell.execute_reply": "2025-12-01T20:09:08.356707Z",
     "shell.execute_reply.started": "2025-12-01T20:09:08.341106Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "EPOCHS = 50\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.2, patience=10, verbose=True\n",
    ")\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
    "\n",
    "print(\"Starting training...\")\n",
    "\n",
    "# ===========================\n",
    "# TRAINING LOOP\n",
    "# ===========================\n",
    "for epoch in range(EPOCHS):\n",
    "    # --- Training Phase ---\n",
    "    model.train()\n",
    "    train_loss, correct, total = 0, 0, 0\n",
    "    \n",
    "    loop = tqdm(dl_train, desc=f\"Epoch {epoch+1}/{EPOCHS}\", leave=False)\n",
    "    for x, y in loop:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x)\n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += y.size(0)\n",
    "        correct += predicted.eq(y).sum().item()\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_train_loss = train_loss / len(dl_train)\n",
    "    train_acc = 100 * correct / total\n",
    "\n",
    "    # --- Validation Phase ---\n",
    "    model.eval()\n",
    "    val_loss, correct, total = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in dl_val:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs, y)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += y.size(0)\n",
    "            correct += predicted.eq(y).sum().item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(dl_val)\n",
    "    val_acc = 100 * correct / total\n",
    "\n",
    "    # Record history\n",
    "    history['train_loss'].append(avg_train_loss)\n",
    "    history['val_loss'].append(avg_val_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_acc'].append(val_acc)\n",
    "\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f\"Epoch {epoch+1}: Train Loss={avg_train_loss:.4f} (Acc {train_acc:.1f}%) | \"\n",
    "              f\"Val Loss={avg_val_loss:.4f} (Acc {val_acc:.1f}%)\")\n",
    "    \n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "# --- Plot Training History ---\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['train_loss'], label='Train Loss', marker='o')\n",
    "plt.plot(history['val_loss'], label='Validation Loss', marker='o')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['train_acc'], label='Train Accuracy', marker='o')\n",
    "plt.plot(history['val_acc'], label='Validation Accuracy', marker='o')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.title(\"Training and Validation Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TimeMAE Configuration\n",
    "\n",
    "This block defines the **hyperparameters for TimeMAE**, a **masked autoencoder for time series**:\n",
    "\n",
    "- **Input & Patching:**  \n",
    "  - Window of 3 seconds sampled at 25 Hz → 75 time steps.  \n",
    "  - Divided into small patches of 5 steps each, forming 15 patches per window.  \n",
    "\n",
    "- **Model Dimensions:**  \n",
    "  - Embedding dimension: 64  \n",
    "  - Attention heads: 4  \n",
    "  - Dropout: 0.2  \n",
    "\n",
    "- **Encoder/Decoder Depth:**  \n",
    "  - Original paper uses deeper stacks (8 encoder, 6 decoder).  \n",
    "  - Here, we reduce depth (4 encoder, 2 decoder) to **avoid overfitting** and because the dataset is smaller than the other they've used in the paper that introduced the idea (like HAR).  \n",
    "\n",
    "- **Masking & Tasks:**  \n",
    "  - Mask ratio: 60% (predict the masked patches).  \n",
    "  - Codebook size for reconstruction: 128  \n",
    "\n",
    "- **Optimization:**  \n",
    "  - Large batch size (1024) for stability  \n",
    "  - Learning rate 0.003, weight decay 1e-4, momentum tau 0.95  \n",
    "\n",
    "- **Loss Weights:**  \n",
    "  - `alpha` and `beta` balance classification (MCC) and reconstruction (MRR) losses.\n",
    "\n",
    "Overall, this config prepares the **TimeMAE model for time series data** while keeping it **lighter and more stable** for a medium-sized, multi-class calf behavior dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T20:09:08.358281Z",
     "iopub.status.busy": "2025-12-01T20:09:08.358058Z",
     "iopub.status.idle": "2025-12-01T20:09:08.374096Z",
     "shell.execute_reply": "2025-12-01T20:09:08.373329Z",
     "shell.execute_reply.started": "2025-12-01T20:09:08.358245Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "class TimeMAEConfig:\n",
    "    UNLABELED_PATH = '/kaggle/input/calf-dl/Time_Adj_Raw_Data.parquet'\n",
    "    \n",
    "    # Hiperparâmetros do Paper\n",
    "    FREQ = 25\n",
    "    WINDOW_SECONDS = 3.0\n",
    "    WINDOW_SIZE = int(FREQ * WINDOW_SECONDS) \n",
    "    PATCH_SIZE = 5   # δ (Delta do paper)\n",
    "    NUM_PATCHES = WINDOW_SIZE // PATCH_SIZE \n",
    "    \n",
    "    # Model Dimensions (Paper usa 64)\n",
    "    EMBED_DIM = 64   \n",
    "    NUM_HEADS = 4    \n",
    "    DROPOUT = 0.2    \n",
    "    \n",
    "    # Depth (Paper: 8 Encoder, 6 Decoder)\n",
    "    # Kaggle Safe: Vamos reduzir um pouco, mas manter a proporção\n",
    "    DEPTH_ENC = 4 \n",
    "    DEPTH_DEC = 2\n",
    "    \n",
    "    # Masking & Tasks\n",
    "    MASK_RATIO = 0.60\n",
    "    CODEBOOK_SIZE = 128 # Vocabulary size\n",
    "    \n",
    "    # Optimization\n",
    "    BATCH_SIZE = 1024\n",
    "    LR = 0.003\n",
    "    WEIGHT_DECAY = 1e-4\n",
    "    MOMENTUM_TAU = 0.95\n",
    "    \n",
    "    # Loss Weights (Paper: alpha=1, beta search 1..10)\n",
    "    ALPHA = 1.0 # Peso MCC (Classificação)\n",
    "    BETA = 1.0  # Peso MRR (Regressão)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unlabeled TimeMAE Dataset\n",
    "\n",
    "This dataset prepares **unlabeled accelerometer windows** for TimeMAE:\n",
    "\n",
    "- Uses sliding windows of 75 time steps (3 s) with a stride of 25 → overlapping windows naturally augment the data.\n",
    "- Returns each window as a **PyTorch tensor** in shape `(channels, time)` → `(3, 75)`.\n",
    "- No labels are needed since TimeMAE is **self-supervised** (masked reconstruction task).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T20:09:08.375210Z",
     "iopub.status.busy": "2025-12-01T20:09:08.374951Z",
     "iopub.status.idle": "2025-12-01T20:09:08.392964Z",
     "shell.execute_reply": "2025-12-01T20:09:08.392301Z",
     "shell.execute_reply.started": "2025-12-01T20:09:08.375193Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Dataset e Collator (Reutilizando lógica otimizada) ---\n",
    "class UnlabeledMaedDataset(Dataset):\n",
    "    def __init__(self, parquet_path, window_size=75, stride=25):\n",
    "        # Stride=25 gera sobreposição para aumentar dados de treino (Data Augmentation natural)\n",
    "        df = pl.read_parquet(parquet_path)\n",
    "        self.signals = df.select(['accX', 'accY', 'accZ']).to_numpy().astype('float32')\n",
    "        self.window_size = window_size\n",
    "        self.indices = [i for i in range(0, len(self.signals) - window_size, stride)]\n",
    "        \n",
    "    def __len__(self): return len(self.indices)\n",
    "    def __getitem__(self, idx):\n",
    "        start = self.indices[idx]\n",
    "        window = self.signals[start : start + self.window_size]\n",
    "        # (3, 75)\n",
    "        return torch.from_numpy(window).permute(1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masking Collator for TimeMAE\n",
    "\n",
    "This collator prepares **masked inputs** for the autoencoder:\n",
    "\n",
    "- Receives a batch of windows `(B, 3, 75)`.\n",
    "- Divides each window into `num_patches` patches.\n",
    "- Randomly selects a fraction (`mask_ratio`, e.g., 60%) of patches to mask.\n",
    "- Returns the batch and a **boolean mask** indicating which patches are masked (`True = masked`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T20:09:08.393940Z",
     "iopub.status.busy": "2025-12-01T20:09:08.393733Z",
     "iopub.status.idle": "2025-12-01T20:09:08.407681Z",
     "shell.execute_reply": "2025-12-01T20:09:08.407130Z",
     "shell.execute_reply.started": "2025-12-01T20:09:08.393915Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class MaskingCollator:\n",
    "    def __init__(self, num_patches, mask_ratio=0.60):\n",
    "        self.num_patches = num_patches\n",
    "        self.mask_ratio = mask_ratio\n",
    "        \n",
    "    def __call__(self, batch):\n",
    "        batch_x = torch.stack(batch) # (B, 3, 75)\n",
    "        B = batch_x.shape[0]\n",
    "        num_masked = int(self.mask_ratio * self.num_patches)\n",
    "        \n",
    "        # Cria máscara booleana (True = Mascarado)\n",
    "        mask = torch.zeros(B, self.num_patches, dtype=torch.bool)\n",
    "        for i in range(B):\n",
    "            rand_idx = torch.randperm(self.num_patches)[:num_masked]\n",
    "            mask[i, rand_idx] = True\n",
    "            \n",
    "        return batch_x, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TimeMAE Model: Building Blocks and Overview\n",
    "\n",
    "This block defines the **core architecture** of the TimeMAE (Masked Autoencoder for Time Series) model.\n",
    "\n",
    "1. **Patch Embedding (`PatchEmbed`)**  \n",
    "   - Converts a 1D time series `(B, 3, T)` into a sequence of **patch tokens** `(B, N_patches, D)`.  \n",
    "   - Uses 1D convolution with kernel size equal to patch size for slicing.  \n",
    "   - Acts as the **input feature encoder** for the transformer.\n",
    "\n",
    "2. **Cross-Attention Block (`CrossAttentionBlock`)**  \n",
    "   - Used in the **decoder** to reconstruct masked patches.  \n",
    "   - Performs multi-head attention between masked queries and visible (encoded) tokens.  \n",
    "   - Includes **residual connections**, layer normalization, and feed-forward network.\n",
    "\n",
    "3. **TimeMAE Pretraining Model (`TimeMAE_Pretrain`)**  \n",
    "   - **Encoder**:  \n",
    "     - Patch embedding + positional embeddings.  \n",
    "     - Transformer encoder processes visible (unmasked) patches.  \n",
    "   - **Decoder**:  \n",
    "     - Receives masked tokens and applies **cross-attention** to visible encoded tokens.  \n",
    "     - Multi-layer decoder reconstructs masked representations.\n",
    "   - **Target Encoder**:  \n",
    "     - Frozen copy of online encoder for stable teacher signals.  \n",
    "     - Updated via **Exponential Moving Average (EMA)**.\n",
    "   - **Codebook**:  \n",
    "     - Discretizes latent embeddings into a finite set for classification-based reconstruction (MCC).  \n",
    "\n",
    "4. **Forward Pass**  \n",
    "   - Takes input windows and a **mask** indicating which patches are masked.  \n",
    "   - Encoder processes **visible patches**.  \n",
    "   - Decoder reconstructs **masked patches** using cross-attention.  \n",
    "   - Target encoder provides reference embeddings for the masked patches.\n",
    "\n",
    "5. **Losses (`get_losses`)**  \n",
    "   - **MRR (Masked Reconstruction Regression)**: MSE between predicted and target embeddings.  \n",
    "   - **MCC (Masked Codebook Classification)**: Cross-entropy using codebook discretization.  \n",
    "   - Combined loss encourages the model to **reconstruct masked patches accurately** while leveraging discrete representations for stability.\n",
    "\n",
    "**Overall Idea:**  \n",
    "TimeMAE learns to predict missing parts of the time series by masking random patches. The encoder-decoder architecture with a **frozen target encoder** stabilizes learning, while the **codebook** allows a hybrid regression+classification objective. For our problem, we reduced the depth of encoder/decoder to avoid **overfitting**, as the dataset is smaller and less complex than datasets used in the original paper.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T20:09:08.408815Z",
     "iopub.status.busy": "2025-12-01T20:09:08.408489Z",
     "iopub.status.idle": "2025-12-01T20:09:08.427953Z",
     "shell.execute_reply": "2025-12-01T20:09:08.427414Z",
     "shell.execute_reply.started": "2025-12-01T20:09:08.408790Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Building Blocks ---\n",
    "class PatchEmbed(nn.Module):\n",
    "    \"\"\"Feature Encoder: Conv1d for slicing\"\"\"\n",
    "    def __init__(self, in_ch=3, patch_size=5, embed_dim=64):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Conv1d(in_ch, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, 3, T) -> (B, N_patches, D)\n",
    "        return self.proj(x).transpose(1, 2)\n",
    "\n",
    "\n",
    "class CrossAttentionBlock(nn.Module):\n",
    "    \"\"\"Decoder block with cross-attention\"\"\"\n",
    "    def __init__(self, dim, num_heads, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.cross_attn = nn.MultiheadAttention(dim, num_heads, dropout=dropout, batch_first=True)\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(dim, dim*4), nn.GELU(), nn.Dropout(dropout), nn.Linear(dim*4, dim)\n",
    "        )\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, query, key_value):\n",
    "        attn_out, _ = self.cross_attn(query, key_value, key_value)\n",
    "        x = self.norm1(query + self.dropout(attn_out))\n",
    "        x = self.norm2(x + self.dropout(self.ffn(x)))\n",
    "        return x\n",
    "\n",
    "\n",
    "class TimeMAE_Pretrain(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        \n",
    "        # Online encoder\n",
    "        self.patch_embed = PatchEmbed(3, cfg.PATCH_SIZE, cfg.EMBED_DIM)\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, cfg.NUM_PATCHES, cfg.EMBED_DIM))\n",
    "        self.mask_token = nn.Parameter(torch.zeros(1, 1, cfg.EMBED_DIM))\n",
    "        nn.init.trunc_normal_(self.pos_embed, std=.02)\n",
    "        nn.init.normal_(self.mask_token, std=.02)\n",
    "        \n",
    "        enc_layer = nn.TransformerEncoderLayer(\n",
    "            cfg.EMBED_DIM, cfg.NUM_HEADS, cfg.EMBED_DIM*4, cfg.DROPOUT,\n",
    "            batch_first=True, norm_first=True\n",
    "        )\n",
    "        self.visible_encoder = nn.TransformerEncoder(enc_layer, cfg.DEPTH_ENC)\n",
    "        self.decoupled_decoder = nn.ModuleList([\n",
    "            CrossAttentionBlock(cfg.EMBED_DIM, cfg.NUM_HEADS, cfg.DROPOUT) \n",
    "            for _ in range(cfg.DEPTH_DEC)\n",
    "        ])\n",
    "        \n",
    "        # Target encoder (copy of online encoder, frozen)\n",
    "        self.target_patch_embed = copy.deepcopy(self.patch_embed)\n",
    "        self.target_visible_encoder = copy.deepcopy(self.visible_encoder)\n",
    "        for p in self.target_patch_embed.parameters(): p.requires_grad = False\n",
    "        for p in self.target_visible_encoder.parameters(): p.requires_grad = False\n",
    "        \n",
    "        # Codebook for discretization\n",
    "        self.codebook = nn.Parameter(torch.randn(cfg.CODEBOOK_SIZE, cfg.EMBED_DIM))\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def update_target_encoder(self):\n",
    "        \"\"\"Update target encoder weights via EMA\"\"\"\n",
    "        m = self.cfg.MOMENTUM_TAU\n",
    "        for param_q, param_k in zip(self.patch_embed.parameters(), self.target_patch_embed.parameters()):\n",
    "            param_k.data = param_k.data * m + param_q.data * (1. - m)\n",
    "        for param_q, param_k in zip(self.visible_encoder.parameters(), self.target_visible_encoder.parameters()):\n",
    "            param_k.data = param_k.data * m + param_q.data * (1. - m)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        B = x.shape[0]\n",
    "        \n",
    "        # Online path\n",
    "        x_patches = self.patch_embed(x) + self.pos_embed\n",
    "        visible_tokens = x_patches[~mask].view(B, -1, self.cfg.EMBED_DIM)\n",
    "        encoded_visible = self.visible_encoder(visible_tokens)\n",
    "        \n",
    "        pos_masked = self.pos_embed.expand(B, -1, -1)[mask].view(B, -1, self.cfg.EMBED_DIM)\n",
    "        decoder_queries = self.mask_token + pos_masked\n",
    "        \n",
    "        x_dec = decoder_queries\n",
    "        for layer in self.decoupled_decoder:\n",
    "            x_dec = layer(query=x_dec, key_value=encoded_visible)\n",
    "        \n",
    "        # Target path\n",
    "        with torch.no_grad():\n",
    "            target_patches = self.target_patch_embed(x) + self.pos_embed\n",
    "            masked_real_tokens = target_patches[mask].view(B, -1, self.cfg.EMBED_DIM)\n",
    "            target_representations = self.target_visible_encoder(masked_real_tokens)\n",
    "            target_representations = F.layer_norm(target_representations, target_representations.shape[-1:])\n",
    "            \n",
    "        return x_dec, target_representations\n",
    "    \n",
    "    def get_losses(self, pred_latents, target_latents):\n",
    "        \"\"\"Compute regression (MRR) and classification (MCC) losses\"\"\"\n",
    "        loss_mrr = F.mse_loss(pred_latents, target_latents)\n",
    "        \n",
    "        flat_targets = target_latents.reshape(-1, self.cfg.EMBED_DIM)\n",
    "        flat_preds = pred_latents.reshape(-1, self.cfg.EMBED_DIM)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            sim_target = torch.matmul(flat_targets, self.codebook.t())\n",
    "            target_ids = torch.argmax(sim_target, dim=-1)\n",
    "            \n",
    "        logits = torch.matmul(flat_preds, self.codebook.t())\n",
    "        loss_mcc = F.cross_entropy(logits, target_ids)\n",
    "        \n",
    "        return loss_mrr, loss_mcc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TimeMAE Pretraining Loop\n",
    "\n",
    "In this block, we **set up and train the TimeMAE model** on unlabeled accelerometer data. First, we initialize the model, move it to the GPU if available, and prepare the unlabeled dataset with sliding windows. A `MaskingCollator` applies random masking to patches during batching, which is the core of the self-supervised training.\n",
    "\n",
    "During training, each batch is passed through the model to obtain predictions for the masked patches and reference embeddings from the frozen target encoder. The combined loss, a weighted sum of **MRR (regression reconstruction)** and **MCC (codebook classification)**, is backpropagated. After each step, the target encoder is updated using **momentum** to stabilize learning.\n",
    "\n",
    "We log periodic progress for batches and compute epoch averages for loss and MRR. The scheduler updates the learning rate based on validation loss trends, and checkpoints are saved after each epoch, with the best model stored separately. Overall, this loop implements **self-supervised pretraining**, teaching the model to reconstruct missing patches from partially observed time series, building robust embeddings for downstream tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T20:09:08.428908Z",
     "iopub.status.busy": "2025-12-01T20:09:08.428681Z",
     "iopub.status.idle": "2025-12-01T20:09:11.330638Z",
     "shell.execute_reply": "2025-12-01T20:09:11.330039Z",
     "shell.execute_reply.started": "2025-12-01T20:09:08.428885Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cfg = TimeMAEConfig()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Model\n",
    "model = TimeMAE_Pretrain(cfg).to(device)\n",
    "\n",
    "# Unlabeled dataset and dataloader\n",
    "ds_ssl = UnlabeledMaedDataset(cfg.UNLABELED_PATH, window_size=cfg.WINDOW_SIZE, stride=25)\n",
    "dl_ssl = DataLoader(\n",
    "    ds_ssl, \n",
    "    batch_size=cfg.BATCH_SIZE, \n",
    "    shuffle=True, \n",
    "    num_workers=2, \n",
    "    pin_memory=True,\n",
    "    collate_fn=MaskingCollator(cfg.NUM_PATCHES, cfg.MASK_RATIO),\n",
    "    drop_last=True \n",
    ")\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=cfg.LR, weight_decay=cfg.WEIGHT_DECAY)\n",
    "\n",
    "# Checkpoint handling\n",
    "checkpoint_path = \"/kaggle/working/timemae_pretrained.pth\"\n",
    "start_epoch = 0\n",
    "best_loss = float('inf')\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    print(f\"Checkpoint found: {checkpoint_path}\")\n",
    "    try:\n",
    "        state = torch.load(checkpoint_path, map_location=device)\n",
    "        if isinstance(state, dict) and 'model_state_dict' in state:\n",
    "            model.load_state_dict(state['model_state_dict'])\n",
    "            if 'optimizer_state_dict' in state:\n",
    "                optimizer.load_state_dict(state['optimizer_state_dict'])\n",
    "            if 'loss' in state:\n",
    "                best_loss = state['loss']\n",
    "        else:\n",
    "            model.load_state_dict(state)\n",
    "        print(\"Weights loaded successfully. Resuming training...\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading checkpoint: {e}. Starting from scratch.\")\n",
    "else:\n",
    "    print(\"No checkpoint found. Starting training from scratch.\")\n",
    "\n",
    "# LR Scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.1, patience=3, verbose=True\n",
    ")\n",
    "\n",
    "# Training loop\n",
    "EPOCHS = 10\n",
    "history = {'loss': [], 'mrr': [], 'mcc': []}\n",
    "\n",
    "print(f\"Starting training: Batch={cfg.BATCH_SIZE}, LR={cfg.LR}, Tau={cfg.MOMENTUM_TAU}\")\n",
    "\n",
    "model.train()\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    total_mrr = 0\n",
    "    total_mcc = 0\n",
    "    steps = len(dl_ssl)\n",
    "    \n",
    "    for batch_idx, (x, mask) in enumerate(dl_ssl):\n",
    "        x, mask = x.to(device), mask.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward\n",
    "        pred_latents, target_latents = model(x, mask)\n",
    "        \n",
    "        # Compute losses\n",
    "        loss_mrr, loss_mcc = model.get_losses(pred_latents, target_latents)\n",
    "        loss = cfg.ALPHA * loss_mcc + cfg.BETA * loss_mrr\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update target encoder via momentum\n",
    "        model.update_target_encoder()\n",
    "        \n",
    "        # Accumulate metrics\n",
    "        total_loss += loss.item()\n",
    "        total_mrr += loss_mrr.item()\n",
    "        total_mcc += loss_mcc.item()\n",
    "        \n",
    "        # Periodic logging\n",
    "        if batch_idx % (steps // 10) == 0 and batch_idx > 0:\n",
    "            print(f\"  Epoch {epoch+1} [{batch_idx}/{steps}] Loss: {loss.item():.4f} (MRR: {loss_mrr.item():.4f})\")\n",
    "    \n",
    "    # Epoch statistics\n",
    "    avg_loss = total_loss / steps\n",
    "    avg_mrr = total_mrr / steps\n",
    "    avg_mcc = total_mcc / steps\n",
    "    history['loss'].append(avg_loss)\n",
    "    \n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    print(f\"End Epoch {epoch+1} | Avg Loss: {avg_loss:.4f} | MRR: {avg_mrr:.4f} | LR: {current_lr}\")\n",
    "    \n",
    "    # Scheduler step\n",
    "    scheduler.step(avg_loss)\n",
    "    \n",
    "    # Save checkpoints\n",
    "    save_dict = {\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': avg_loss,\n",
    "    }\n",
    "    torch.save(save_dict, \"timemae_last.pth\")\n",
    "    \n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        torch.save(model.state_dict(), \"timemae_pretrained.pth\")\n",
    "        print(f\"New best model saved! (Loss: {best_loss:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T20:09:11.331636Z",
     "iopub.status.busy": "2025-12-01T20:09:11.331389Z",
     "iopub.status.idle": "2025-12-01T20:09:11.381007Z",
     "shell.execute_reply": "2025-12-01T20:09:11.380408Z",
     "shell.execute_reply.started": "2025-12-01T20:09:11.331612Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TimeMAE_Classifier(nn.Module):\n",
    "    def __init__(self, cfg, num_classes):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        \n",
    "        # Backbone\n",
    "        self.patch_embed = PatchEmbed(3, cfg.PATCH_SIZE, cfg.EMBED_DIM)\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, cfg.NUM_PATCHES, cfg.EMBED_DIM))\n",
    "        \n",
    "        # Transformer Encoder\n",
    "        enc_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=cfg.EMBED_DIM, \n",
    "            nhead=cfg.NUM_HEADS, \n",
    "            dim_feedforward=cfg.EMBED_DIM*4, \n",
    "            dropout=cfg.DROPOUT, \n",
    "            batch_first=True, \n",
    "            norm_first=True\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(enc_layer, cfg.DEPTH_ENC)\n",
    "        \n",
    "        # Classification Head\n",
    "        self.norm = nn.LayerNorm(cfg.EMBED_DIM)\n",
    "        self.head = nn.Linear(cfg.EMBED_DIM, num_classes)\n",
    "        nn.init.trunc_normal_(self.pos_embed, std=.02)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.patch_embed(x) + self.pos_embed\n",
    "        x = self.encoder(x)\n",
    "        x = x.mean(dim=1)\n",
    "        x = self.norm(x)\n",
    "        logits = self.head(x)\n",
    "        return logits\n",
    "\n",
    "    def load_pretrained(self, path):\n",
    "        print(f\"Loading pretrained weights from: {path}\")\n",
    "        checkpoint = torch.load(path, map_location='cpu')\n",
    "        \n",
    "        model_dict = self.state_dict()\n",
    "        pretrained_dict = {}\n",
    "        \n",
    "        for k, v in checkpoint.items():\n",
    "            if k.startswith('patch_embed') or k.startswith('pos_embed'):\n",
    "                pretrained_dict[k] = v\n",
    "            elif k.startswith('visible_encoder'):\n",
    "                pretrained_dict[k.replace('visible_encoder', 'encoder')] = v\n",
    "        \n",
    "        # Keep only keys that exist in the classifier\n",
    "        pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "        \n",
    "        missing, unexpected = self.load_state_dict(pretrained_dict, strict=False)\n",
    "        print(\"Pretrained weights loaded. Decoder and target encoder ignored.\")\n",
    "        print(f\"Missing keys (likely the classification head): {missing}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop - TimeMAE\n",
    "\n",
    "---\n",
    "\n",
    "Now, we can finally test the model, using our unlabeled data, with +2000h.\n",
    "\n",
    "---\n",
    "\n",
    "### Results\n",
    "\n",
    "As we can see, it didn't even get better than the baseline when talking about accuracy, getting close to 54% at best, with different hiperparameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T20:09:11.382093Z",
     "iopub.status.busy": "2025-12-01T20:09:11.381807Z",
     "iopub.status.idle": "2025-12-01T20:09:11.409387Z",
     "shell.execute_reply": "2025-12-01T20:09:11.408732Z",
     "shell.execute_reply.started": "2025-12-01T20:09:11.382067Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "num_classes = len(classes)\n",
    "model_ft = TimeMAE_Classifier(cfg, num_classes).to(device)\n",
    "\n",
    "import os\n",
    "if os.path.exists(\"timemae_pretrained.pth\"):\n",
    "    model_ft.load_pretrained(\"timemae_pretrained.pth\")\n",
    "else:\n",
    "    print(\"Warning: Pretrained file not found. Training from scratch.\")\n",
    "\n",
    "# Supervised dataloaders\n",
    "dl_train = DataLoader(ds_train, batch_size=256, shuffle=True, num_workers=2)\n",
    "dl_val = DataLoader(ds_val, batch_size=256, shuffle=False, num_workers=2)\n",
    "\n",
    "# Optimizer and loss\n",
    "optimizer = torch.optim.Adam(model_ft.parameters(), lr=0.002, weight_decay=1e-3)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# Training loop\n",
    "print(f\"\\nStarting fine-tuning on {num_classes} classes...\")\n",
    "EPOCHS = 200\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model_ft.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for x, y in dl_train:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logits = model_ft(x)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, predicted = logits.max(1)\n",
    "        total += y.size(0)\n",
    "        correct += predicted.eq(y).sum().item()\n",
    "        \n",
    "    # Validation\n",
    "    model_ft.eval()\n",
    "    val_loss = 0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in dl_val:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = model_ft(x)\n",
    "            loss = criterion(logits, y)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = logits.max(1)\n",
    "            val_total += y.size(0)\n",
    "            val_correct += predicted.eq(y).sum().item()\n",
    "            \n",
    "    # Logs\n",
    "    acc_train = 100 * correct / total\n",
    "    acc_val = 100 * val_correct / val_total\n",
    "    avg_train_loss = train_loss / len(dl_train)\n",
    "    avg_val_loss = val_loss / len(dl_val)\n",
    "\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f\"Epoch {epoch+1}: Train Loss={avg_train_loss:.4f} (Acc {acc_train:.1f}%) | \"\n",
    "              f\"Val Loss={avg_val_loss:.4f} (Acc {acc_val:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Series Augmentation\n",
    "\n",
    "This class implements **data augmentation for time series**. The `weak_aug` method applies small additive noise and slight scaling to the signals, simulating natural sensor variability. The `strong_aug` method builds on this by additionally performing **segment permutation** (shuffling parts of the signal) and **time masking** (zeroing out random segments), which helps the model learn to be robust to missing or reordered information. These augmentations are key for semi-supervised approaches like FixMatch, where the model benefits from diverse views of the same data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T20:09:11.410262Z",
     "iopub.status.busy": "2025-12-01T20:09:11.410064Z",
     "iopub.status.idle": "2025-12-01T20:09:11.418948Z",
     "shell.execute_reply": "2025-12-01T20:09:11.418242Z",
     "shell.execute_reply.started": "2025-12-01T20:09:11.410240Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================================== \n",
    "# 1. TIME SERIES AUGMENTATION CLASS\n",
    "# ==============================================================================\n",
    "class TimeSeriesAugmentations:\n",
    "    def __init__(self, device):\n",
    "        self.device = device\n",
    "\n",
    "    def weak_aug(self, x):\n",
    "        \"\"\"Weak augmentation: small additive noise and scaling\"\"\"\n",
    "        B, C, T = x.shape\n",
    "        sigma = 0.05\n",
    "        noise = torch.randn_like(x, device=self.device) * sigma   # Additive noise\n",
    "        scale = torch.rand(B, 1, 1, device=self.device) * 0.2 + 0.9  # Multiplicative scale\n",
    "        return (x * scale) + noise\n",
    "\n",
    "    def strong_aug(self, x):\n",
    "        \"\"\"Strong augmentation: segment permutation + time masking\"\"\"\n",
    "        x = self.weak_aug(x)\n",
    "        B, C, T = x.shape\n",
    "        x_aug = x.clone()\n",
    "        \n",
    "        # Segment permutation\n",
    "        if T > 10:\n",
    "            num_segs = np.random.randint(2, 5)\n",
    "            seg_len = T // num_segs\n",
    "            for i in range(B):\n",
    "                perm = torch.randperm(num_segs)\n",
    "                segs = [x[i, :, p*seg_len : (p+1)*seg_len] for p in perm]\n",
    "                shuffled = torch.cat(segs, dim=1)\n",
    "                \n",
    "                # Adjust length if needed\n",
    "                curr_len = shuffled.shape[1]\n",
    "                if curr_len < T:\n",
    "                    pad = torch.zeros(C, T - curr_len, device=self.device)\n",
    "                    shuffled = torch.cat([shuffled, pad], dim=1)\n",
    "                elif curr_len > T:\n",
    "                    shuffled = shuffled[:, :T]\n",
    "                x_aug[i] = shuffled\n",
    "\n",
    "        # Time masking\n",
    "        mask_ratio = 0.2\n",
    "        mask_len = int(T * mask_ratio)\n",
    "        for i in range(B):\n",
    "            start = np.random.randint(0, max(1, T - mask_len))\n",
    "            x_aug[i, :, start : start+mask_len] = 0.0\n",
    "            \n",
    "        return x_aug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FixMatch Semi-Supervised Training\n",
    "\n",
    "This block implements the **FixMatch semi-supervised framework** using a ResNet baseline for time series classification. It sets up the model, optimizer, learning rate scheduler, and checkpoint handling. The key idea is to combine **supervised loss on labeled data** with an **unsupervised loss on unlabeled data**. The unlabeled data is augmented twice: once weakly to generate pseudo-labels, and once strongly to enforce consistency. Only pseudo-labels with high confidence (above `FIXMATCH_THRESHOLD`) contribute to the unsupervised loss. Augmentations like additive noise, scaling, segment permutation, and time masking increase robustness. The code also manages preprocessor normalization, tracks metrics like training accuracy and mask rate, and saves checkpoints when validation performance improves.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T23:43:02.835943Z",
     "iopub.status.busy": "2025-12-01T23:43:02.835639Z",
     "iopub.status.idle": "2025-12-02T00:26:28.795112Z",
     "shell.execute_reply": "2025-12-02T00:26:28.794189Z",
     "shell.execute_reply.started": "2025-12-01T23:43:02.835916Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH = \"fixmatch_resnet.pth\"\n",
    "NUM_CLASSES = 19\n",
    "LR = 10        \n",
    "EPOCHS = 80\n",
    "FIXMATCH_THRESHOLD = 0.90 \n",
    "LAMBDA_U = 15.0          \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ResNetBaseline(NUM_CLASSES, in_channels=4).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=1e-3)\n",
    "augmenter = TimeSeriesAugmentations(device)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=3, verbose=True\n",
    ")\n",
    "\n",
    "# Make sure the preprocessor exists\n",
    "if 'preprocessor' not in globals():\n",
    "    preprocessor = SensorPreprocessor()\n",
    "    # Fit preprocessor on labeled training data\n",
    "    preprocessor.fit(train_df)\n",
    "\n",
    "start_epoch = 0\n",
    "best_val_acc = 0.0\n",
    "\n",
    "# Load checkpoint if exists\n",
    "if os.path.exists(CHECKPOINT_PATH):\n",
    "    print(f\"Checkpoint found: {CHECKPOINT_PATH}\")\n",
    "    try:\n",
    "        checkpoint = torch.load(CHECKPOINT_PATH, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        best_val_acc = checkpoint.get('best_val_acc', 0.0)\n",
    "        print(f\"Resuming from epoch {start_epoch}. Best validation accuracy: {best_val_acc:.2f}%\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading checkpoint: {e}. Starting from scratch.\")\n",
    "else:\n",
    "    print(\"Starting FixMatch training from scratch.\")\n",
    "\n",
    "# Infinite iterator for unlabeled data\n",
    "def cycle(iterable):\n",
    "    while True:\n",
    "        for x in iterable:\n",
    "            yield x\n",
    "unlabeled_iter = cycle(dl_ssl)\n",
    "\n",
    "# Move preprocessor mean/std to GPU\n",
    "mean_gpu = torch.tensor(preprocessor.mean, device=device, dtype=torch.float32).view(1, 3, 1)\n",
    "std_gpu = torch.tensor(preprocessor.std, device=device, dtype=torch.float32).view(1, 3, 1)\n",
    "\n",
    "print(f\"Running FixMatch (Threshold={FIXMATCH_THRESHOLD}, Lambda={LAMBDA_U}) for {EPOCHS} epochs...\")\n",
    "\n",
    "for epoch in range(start_epoch, EPOCHS):\n",
    "    model.train()\n",
    "    \n",
    "    train_loss_acc = 0\n",
    "    sup_loss_acc = 0\n",
    "    unsup_loss_acc = 0\n",
    "    mask_count = 0\n",
    "    total_unlabeled = 0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    \n",
    "    for batch_idx, (inputs_x, targets_x) in enumerate(dl_train):\n",
    "        inputs_x, targets_x = inputs_x.to(device), targets_x.to(device)\n",
    "        \n",
    "        # Unlabeled batch\n",
    "        try:\n",
    "            batch_u = next(unlabeled_iter)\n",
    "            inputs_u_raw = batch_u[0] if isinstance(batch_u, (list, tuple)) else batch_u\n",
    "        except:\n",
    "            unlabeled_iter = cycle(dl_ssl)\n",
    "            inputs_u_raw = next(unlabeled_iter)[0]\n",
    "        inputs_u_raw = inputs_u_raw.to(device)\n",
    "        \n",
    "        # Convert 3 channels -> 4 channels on-the-fly\n",
    "        with torch.no_grad():\n",
    "            u_norm = (inputs_u_raw - mean_gpu) / std_gpu\n",
    "            u_mag = torch.sqrt(torch.sum(u_norm**2, dim=1, keepdim=True))\n",
    "            inputs_u = torch.cat([u_norm, u_mag], dim=1)\n",
    "        total_unlabeled += inputs_u.size(0)\n",
    "        \n",
    "        # Supervised loss (weak augment)\n",
    "        inputs_x_aug = augmenter.weak_aug(inputs_x)\n",
    "        logits_x = model(inputs_x_aug)\n",
    "        loss_sup = nn.CrossEntropyLoss(weight=class_weights)(logits_x, targets_x)\n",
    "        \n",
    "        # Training accuracy\n",
    "        with torch.no_grad():\n",
    "            _, pred_x = logits_x.max(1)\n",
    "            train_correct += pred_x.eq(targets_x).sum().item()\n",
    "            train_total += inputs_x.size(0)\n",
    "        \n",
    "        # Unsupervised loss (FixMatch)\n",
    "        with torch.no_grad():\n",
    "            inputs_u_weak = augmenter.weak_aug(inputs_u)\n",
    "            logits_u_weak = model(inputs_u_weak)\n",
    "            probs_u = torch.softmax(logits_u_weak, dim=1)\n",
    "            max_probs, pseudo_label = torch.max(probs_u, dim=1)\n",
    "            mask = max_probs.ge(FIXMATCH_THRESHOLD).float()\n",
    "            mask_count += mask.sum().item()\n",
    "        \n",
    "        inputs_u_strong = augmenter.strong_aug(inputs_u)\n",
    "        logits_u_strong = model(inputs_u_strong)\n",
    "        loss_u_unreduced = nn.CrossEntropyLoss(reduction='none')(logits_u_strong, pseudo_label)\n",
    "        loss_unsup = (loss_u_unreduced * mask).mean()\n",
    "        \n",
    "        # Total loss\n",
    "        loss = loss_sup + (LAMBDA_U * loss_unsup)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss_acc += loss.item()\n",
    "        sup_loss_acc += loss_sup.item()\n",
    "        unsup_loss_acc += loss_unsup.item()\n",
    "    \n",
    "    # Epoch metrics\n",
    "    avg_train_loss = train_loss_acc / len(dl_train)\n",
    "    avg_sup = sup_loss_acc / len(dl_train)\n",
    "    avg_unsup_weighted = (unsup_loss_acc / len(dl_train)) * LAMBDA_U\n",
    "    mask_rate = mask_count / max(total_unlabeled, 1)\n",
    "    train_acc = 100. * train_correct / train_total\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in dl_val:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            loss = nn.CrossEntropyLoss(weight=class_weights)(logits, y)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = logits.max(1)\n",
    "            total += y.size(0)\n",
    "            correct += predicted.eq(y).sum().item()\n",
    "    avg_val_loss = val_loss / len(dl_val)\n",
    "    val_acc = 100. * correct / total\n",
    "    \n",
    "    scheduler.step(avg_val_loss)\n",
    "    \n",
    "    # Logging\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} | Train Loss: {avg_train_loss:.3f} [Sup: {avg_sup:.3f}, Unsup: {avg_unsup_weighted:.3f}]\")\n",
    "    print(f\"   Train Acc: {train_acc:.2f}% | Mask Rate: {mask_rate:.1%}\")\n",
    "    print(f\"   Val Loss:  {avg_val_loss:.4f} | Val Acc:   {val_acc:.2f}%\")\n",
    "    \n",
    "    # Checkpoint\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        print(f\"New best validation accuracy: {best_val_acc:.2f}%\")\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'best_val_acc': best_val_acc,\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "        }, CHECKPOINT_PATH)\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        torch.save(model.state_dict(), f\"fixmatch_ep{epoch+1}.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations on TimeMAE & FixMatch Performance\n",
    "\n",
    "In our experiments, TimeMAE and the FixMatch pipeline **did not outperform simpler models** like Random Forest or LSTM+CNN, with accuracy around 54–56%. Several factors likely contributed:\n",
    "\n",
    "- **Data scarcity:** Masked autoencoders (TimeMAE) and semi-supervised approaches require substantial unlabeled data to learn meaningful representations. With limited calves and short time series, the models may not generalize well.  \n",
    "- **Overly complex models:** TimeMAE's encoder-decoder architecture has many parameters relative to the dataset size. Even reducing depth may not prevent overfitting.  \n",
    "- **Augmentation sensitivity:** Transformations such as segment permutation or time masking may disrupt behavior patterns more than they help, especially for short windows (3s).  \n",
    "- **Representation misalignment:** Autoencoder latent spaces may not capture discriminative features needed for downstream classification, leading to weak pseudo-labels and poor unsupervised loss contribution.\n",
    "\n",
    "Overall, these methods are **data-hungry and sensitive to hyperparameters**, which explains why simpler supervised models performed better in this problem.\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8827100,
     "sourceId": 13856486,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

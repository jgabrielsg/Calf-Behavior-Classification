{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13856486,"sourceType":"datasetVersion","datasetId":8827100}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# AcTBeCalf - Testing the Dataset\n\n---\n\n**Group:**\n- Jo√£o Gabriel\n- Gustavo Tironi\n\n**Subject:**\n- Deep Learning - D√°rio Oliveira\n\n---\n\n### Objective\n\n...\n","metadata":{}},{"cell_type":"markdown","source":"### Setting the Seeds","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\nimport pandas as pd\nimport polars as pl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px  # For interactive graphics\nimport random\nimport os\n\ndef set_seed(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n\nset_seed(42)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Setup done. Using: {device}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-01T20:08:55.624364Z","iopub.execute_input":"2025-12-01T20:08:55.624804Z","iopub.status.idle":"2025-12-01T20:08:55.636266Z","shell.execute_reply.started":"2025-12-01T20:08:55.624732Z","shell.execute_reply":"2025-12-01T20:08:55.635480Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Configurations\n\n---\n\nAll the parameters we'll use during training and testing, also with paths and dataset information (such as FREQ)","metadata":{}},{"cell_type":"code","source":"class Config:\n    LABELED_PATH = '/kaggle/input/calf-dl/AcTBeCalf.parquet'\n    UNLABELED_PATH = '/kaggle/input/calf-dl/Time_Adj_Raw_Data.parquet'\n    \n    # Parameters\n    FREQ = 25  # Hz\n    WINDOW_SECONDS = 3\n    WINDOW_SIZE = FREQ * WINDOW_SECONDS # 250 samples\n    CHANNELS = 3 # X, Y, Z\n    \n    # Train\n    BATCH_SIZE = 64\n    NUM_WORKERS = 2 # Using 2, with more than this it may struggle\n\nprint(\"Config done\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T20:08:55.637361Z","iopub.execute_input":"2025-12-01T20:08:55.637590Z","iopub.status.idle":"2025-12-01T20:08:55.650154Z","shell.execute_reply.started":"2025-12-01T20:08:55.637566Z","shell.execute_reply":"2025-12-01T20:08:55.649434Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### General Inspection\n\n---\n\nLooking at all the info from the dataset, passing through and catching any mistakes that the new parquet might have before we start using the data","metadata":{}},{"cell_type":"code","source":"print(\"INSPECTING LABELED DATASET (AcTBeCalf)\")\n\ntry:\n    df_labeled = pd.read_parquet(Config.LABELED_PATH)\n    \n    # Basic Info\n    print(f\"Shape: {df_labeled.shape}\")\n    print(\"Columns:\", df_labeled.columns.tolist())\n    print(\"\\nData Types:\")\n    print(df_labeled.dtypes)\n    \n    # Null Check\n    print(\"\\nMissing Values (NaNs) per column:\")\n    null_counts = df_labeled.isnull().sum()\n    print(null_counts[null_counts > 0])\n    print(\"\\n[ANALYSIS] calfId Column:\")\n    unique_calves = df_labeled['calfId'].unique()\n    print(f\"Number of unique calves: {len(unique_calves)}\")\n    print(f\"First 10 unique values: {unique_calves[:10]}\")\n    \n    if df_labeled['calfId'].isnull().all():\n        print(\"'calfId' column is NaN. Subject-based split is impossible.\")\n    \n    print(\"\\n[ANALYSIS] behaviour Column:\")\n    raw_labels = df_labeled['behaviour'].astype(str).unique()\n    print(f\"Total unique raw labels: {len(raw_labels)}\")\n    print(\"Sample of labels (First 20):\")\n    print(raw_labels[:530])\n    \n    print(\"\\nLabel Counts (Top 10 most frequent):\")\n    print(df_labeled['behaviour'].astype(str).value_counts().head(10))\n    \n    print(\"\\nLabel Counts (Top 10 LEAST frequent - Potential split errors):\")\n    print(df_labeled['behaviour'].astype(str).value_counts().tail(10))\n\n    # 5. Analyze 'segId'\n    print(\"\\n[ANALYSIS] segId Column:\")\n    n_segments = df_labeled['segId'].nunique()\n    print(f\"Total unique segments: {n_segments}\")\n\nexcept Exception as e:\n    print(f\"Error inspecting labeled data: {e}\")\n\nprint(\"\\n\" + \"=\"*50 + \"\\n\")\n\nprint(\"--- INSPECTING UNLABELED DATASET (Time_Adj_Raw_Data) ---\")\n\ntry:\n    df_unlabeled_head = pl.scan_parquet(Config.UNLABELED_PATH).fetch(5)\n    \n    print(\"Unlabeled Data Schema:\")\n    print(df_unlabeled_head.schema)\n    \n    print(\"\\nFirst 5 rows:\")\n    print(df_unlabeled_head)\n    \nexcept Exception as e:\n    print(f\"Error inspecting unlabeled data: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T20:08:55.651480Z","iopub.execute_input":"2025-12-01T20:08:55.651728Z","iopub.status.idle":"2025-12-01T20:08:59.169942Z","shell.execute_reply.started":"2025-12-01T20:08:55.651711Z","shell.execute_reply":"2025-12-01T20:08:59.169065Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class LabeledCalfDataset(Dataset):\n    def __init__(self, parquet_path, window_size=250):\n        print(f\"Loading Labeled Dataset: {parquet_path}...\")\n        self.data = pd.read_parquet(parquet_path)\n        \n        # Map labels to integers for consistent ordering\n        cats = sorted(self.data['behaviour'].unique())\n        self.label_map = {label: i for i, label in enumerate(cats)}\n        self.int_to_label = {i: label for label, i in self.label_map.items()}\n        \n        self.indices = []\n        \n        # Group by segId to avoid breaking windows\n        for seg_id, group in self.data.groupby('segId'):\n            n = len(group)\n            if n >= window_size:\n                start_global = group.index[0]\n                # Stride = window_size // 2 (50% overlap for natural data augmentation)\n                for i in range(0, n - window_size + 1, window_size // 2):\n                    self.indices.append((start_global + i, start_global + i + window_size))\n        \n        self.signals = self.data[['accX', 'accY', 'accZ']].values.astype('float32')\n        \n        # Map string labels to integer codes\n        self.labels = self.data['behaviour'].map(self.label_map).values.astype('int64')\n        print(f\"Labeled Dataset Ready: {len(self.indices)} samples, {len(cats)} classes.\")\n\n    def __len__(self):\n        return len(self.indices)\n        \n    def __getitem__(self, idx):\n        s, e = self.indices[idx]\n        x = self.signals[s:e]\n        y = self.labels[s]\n        # Transpose (Time, Channel) -> (Channel, Time) for PyTorch\n        return torch.tensor(x).permute(1, 0), torch.tensor(y, dtype=torch.long)\n\n\nclass UnlabeledCalfDataset(Dataset):\n    def __init__(self, parquet_path, window_size=250):\n        print(f\"Loading Unlabeled Dataset: {parquet_path}...\")\n        # Use Polars for memory efficiency\n        df = pl.read_parquet(parquet_path)\n        \n        self.signals = df.select(['accX', 'accY', 'accZ']).to_numpy().astype('float32')\n        timestamps = df.select('dateTime').to_numpy().flatten()  # array of int64 (ns) or datetime\n        \n        self.valid_indices = []\n        total = len(df)\n        stride = window_size  # No overlap for speed\n        \n        # Simplified gap detection logic\n        limit_ns = window_size * 40 * 1_000_000 * 1.1\n        print(\"Calculating valid indices (ignoring gaps)...\")\n        # Vectorized approach: check temporal consistency\n        times = timestamps[::stride]  # pick start times\n        \n        # Simplified implementation: assume continuous data except for large gaps\n        for i in range(0, total - window_size, stride):\n             self.valid_indices.append(i)\n             \n        print(f\"Unlabeled Dataset Ready: {len(self.valid_indices)} samples.\")\n\n    def __len__(self):\n        return len(self.valid_indices)\n        \n    def __getitem__(self, idx):\n        s = self.valid_indices[idx]\n        x = self.signals[s : s + Config.WINDOW_SIZE]\n        return torch.tensor(x).permute(1, 0), torch.tensor(-1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T20:08:59.170757Z","iopub.execute_input":"2025-12-01T20:08:59.171071Z","iopub.status.idle":"2025-12-01T20:08:59.228931Z","shell.execute_reply.started":"2025-12-01T20:08:59.171052Z","shell.execute_reply":"2025-12-01T20:08:59.228164Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Dataset instantiation\nds_labeled = LabeledCalfDataset(Config.LABELED_PATH, Config.WINDOW_SIZE)\nds_unlabeled = UnlabeledCalfDataset(Config.UNLABELED_PATH, Config.WINDOW_SIZE)\n\n# Quick check of the first sample\nx, y = ds_labeled[0]\nprint(f\"\\nTensor overview:\")\nprint(f\"Input Shape (C, L): {x.shape} (Expected: 3, {Config.WINDOW_SIZE})\")\nprint(f\"Label: {y} ('{ds_labeled.int_to_label[y.item()]}')\")\nprint(f\"Data type: {x.dtype}\")\n\n# DataLoader setup\ndl_check = DataLoader(ds_labeled, batch_size=32, shuffle=True)\nbatch_x, batch_y = next(iter(dl_check))\nprint(f\"Batch Shape: {batch_x.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T20:08:59.230404Z","iopub.execute_input":"2025-12-01T20:08:59.230606Z","iopub.status.idle":"2025-12-01T20:09:06.590698Z","shell.execute_reply.started":"2025-12-01T20:08:59.230590Z","shell.execute_reply":"2025-12-01T20:09:06.590007Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Quick count using the Dataset's internal DataFrame\ndf_counts = ds_labeled.data['behaviour'].value_counts().reset_index()\ndf_counts.columns = ['behaviour', 'count']\n\nplt.figure(figsize=(10, 10))\nsns.barplot(data=df_counts, x='count', y='behaviour', palette='viridis')\nplt.title(\"Behavior Distribution (Labeled Set)\")\nplt.xlabel(\"Number of Samples (Raw Rows)\")\nplt.xscale('log')  # Log scale helps visualize rare classes\nplt.grid(axis='x', alpha=0.3)\nplt.show()\n\nprint(\"There are rare classes (Vocalization, Grooming|None) and very common classes.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T20:09:06.591626Z","iopub.execute_input":"2025-12-01T20:09:06.591880Z","iopub.status.idle":"2025-12-01T20:09:07.430077Z","shell.execute_reply.started":"2025-12-01T20:09:06.591854Z","shell.execute_reply":"2025-12-01T20:09:07.429329Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_signal(dataset, label_name=None, index=None):\n    \"\"\"Plots the 3-axis accelerometer signal from a random window of a specific class.\"\"\"\n    \n    # If no explicit index is given, sample a window belonging to the requested class\n    if index is None:\n        target_int = dataset.label_map[label_name]\n        candidates = [i for i, idxs in enumerate(dataset.indices) \n                      if dataset.labels[idxs[0]] == target_int]\n        if not candidates:\n            return print(f\"No data available for {label_name}\")\n        idx = random.choice(candidates)\n    else:\n        idx = index\n\n    # Retrieve the tensor window and its label\n    x_tensor, y_tensor = dataset[idx]\n    label_str = dataset.int_to_label[y_tensor.item()]\n    \n    # Convert the tensor (channels-first) to a DataFrame for plotting\n    data_np = x_tensor.permute(1, 0).numpy()\n    df_plot = pd.DataFrame(\n        data_np, \n        columns=['X (Up/Down)', 'Y (Forward/Backward)', 'Z (Left/Right)']\n    )\n    df_plot['Time'] = np.arange(len(df_plot)) / Config.FREQ\n    \n    # Create interactive plot\n    fig = px.line(\n        df_plot,\n        x='Time',\n        y=['X (Up/Down)', 'Y (Forward/Backward)', 'Z (Left/Right)'],\n        title=f\"Sample of Behavior: {label_str.upper()} (Index {idx})\"\n    )\n    fig.update_layout(yaxis_title=\"Acceleration (g)\", xaxis_title=\"Seconds\")\n    fig.show()\n\nplot_signal(ds_labeled, label_name='lying')    # Should appear nearly flat\nplot_signal(ds_labeled, label_name='running')  # Should show peaks and valleys","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T20:09:07.430897Z","iopub.execute_input":"2025-12-01T20:09:07.431220Z","iopub.status.idle":"2025-12-01T20:09:07.571677Z","shell.execute_reply.started":"2025-12-01T20:09:07.431196Z","shell.execute_reply":"2025-12-01T20:09:07.570901Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Random sample to analyse\nidx_rnd = random.randint(0, len(ds_unlabeled)-1)\nx_u, _ = ds_unlabeled[idx_rnd]\n\ndata_np = x_u.permute(1, 0).numpy()\ndf_u = pd.DataFrame(data_np, columns=['X', 'Y', 'Z'])\ndf_u['Time'] = np.arange(len(df_u)) / Config.FREQ\n\nfig = px.line(df_u, x='Time', y=['X', 'Y', 'Z'], \n              title=f\"Unlabeled sample (Index {idx_rnd})\")\nfig.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T20:09:07.572548Z","iopub.execute_input":"2025-12-01T20:09:07.572829Z","iopub.status.idle":"2025-12-01T20:09:07.621868Z","shell.execute_reply.started":"2025-12-01T20:09:07.572802Z","shell.execute_reply":"2025-12-01T20:09:07.621171Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ndf_full = pd.read_parquet(Config.LABELED_PATH)\n\ndef map_behavior(label):\n    # Convert to lowercase and string to avoid parsing issues\n    label = str(label).lower().strip()\n    \n    # 1. RARE EVENTS (Highest priority because they are short and uncommon)\n    if any(x in label for x in ['cough', 'fall', 'vocalisation']):\n        return 'rare_event'\n        \n    # 2. ABNORMAL BEHAVIORS\n    if any(x in label for x in ['cross-suckle', 'tongue', 'abnormal']):\n        return 'abnormal'\n        \n    # 3. SRS (Self-Reactive: scratch, rub, stretch)\n    if any(x in label for x in ['scratch', 'rub', 'stretch', 'srs']):\n        return 'srs'\n        \n    # 4. ELIMINATION\n    if 'defecat' in label or 'urinat' in label:\n        return 'elimination'\n        \n    # 5. PLAY BEHAVIORS ‚Äî High-energy activities\n    # Includes jump, headbutt, mount, playing with objects\n    if any(x in label for x in ['play', 'jump', 'headbutt', 'mount']):\n        return 'play'\n        \n    # 6. SOCIAL INTERACTION\n    # The paper groups \"nudge\" and \"social sniff\" here.\n    if 'social' in label or 'nudge' in label:\n        return 'social_interaction'\n        \n    # 7. RUMINATION\n    if 'ruminat' in label:\n        return 'rumination'\n        \n    # 8. DRINKING\n    if 'drink' in label:\n        return 'drinking'\n        \n    # 9. EATING\n    if 'eat' in label:\n        return 'eating'\n        \n    # 10. EXPLORATION (Non-social sniffing)\n    if 'sniff' in label:\n        return 'sniff'\n        \n    # 11. ORAL MANIPULATION\n    if 'oral' in label or 'manipulation' in label:\n        return 'oral_manipulation'\n        \n    # 12. GROOMING (Self-grooming)\n    # \"social_groom\" would have been caught earlier under social interaction.\n    if 'groom' in label:\n        return 'grooming'\n        \n    # 13. TRANSITIONS (Checked before static postures)\n    if 'rising' in label:\n        return 'rising'\n    if 'lying down' in label or 'lying-down' in label:\n        return 'lying_down_action'\n        \n    # 14. LOCOMOTION\n    if 'run' in label:\n        return 'running'\n    if 'walk' in label or 'backward' in label:\n        return 'walking'\n        \n    # 15. BASE POSTURES (Fallback)\n    if 'ly' in label:  # captures \"lying\"\n        return 'lying'\n    if 'stand' in label:\n        return 'standing'\n        \n    return 'other'\n\n# Apply taxonomy mapping based on the behavioral paper\nprint(\"Applying behavior taxonomy...\")\ndf_full['behaviour_clean'] = df_full['behaviour'].apply(map_behavior).astype('category')\n\n# Display resulting classes\nclasses = sorted(df_full['behaviour_clean'].unique())\nprint(f\"Mapped Classes ({len(classes)}):\")\nfor c in classes:\n    print(f\"  - {c}\")\n\n# Replace categorical labels with integer indices\nlabel_map = {c: i for i, c in enumerate(classes)}\nint_to_label = {i: c for c, i in label_map.items()}\ndf_full['label_code'] = df_full['behaviour_clean'].map(label_map).astype(int)\n\n# --- SUBJECT-INDEPENDENT TRAINING SPLIT ---\nunique_calves = df_full['calfId'].unique()\n\nif len(unique_calves) > 5:\n    print(\"\\nSplitting by subject (calfId)\")\n    train_ids, temp_ids = train_test_split(unique_calves, test_size=0.30, random_state=42)\n    val_ids, test_ids = train_test_split(temp_ids, test_size=0.50, random_state=42)\n    col_split = 'calfId'\n    \n    train_df = df_full[df_full['calfId'].isin(train_ids)].reset_index(drop=True)\n    val_df = df_full[df_full['calfId'].isin(val_ids)].reset_index(drop=True)\n    test_df = df_full[df_full['calfId'].isin(test_ids)].reset_index(drop=True)\n\nelse:\n    print(\"\\nSplitting by segment (few calf IDs available)\")\n    # Safe fallback in case calfId is unreliable\n    seg_ids = df_full['segId'].unique()\n    train_ids, temp_ids = train_test_split(seg_ids, test_size=0.30, random_state=42)\n    val_ids, test_ids = train_test_split(temp_ids, test_size=0.50, random_state=42)\n    \n    train_df = df_full[df_full['segId'].isin(train_ids)].reset_index(drop=True)\n    val_df = df_full[df_full['segId'].isin(val_ids)].reset_index(drop=True)\n    test_df = df_full[df_full['segId'].isin(test_ids)].reset_index(drop=True)\n\n# Compute class weights for handling imbalance\ncount_series = train_df['label_code'].value_counts().sort_index()\ncounts = np.zeros(len(classes))\nfor idx, val in count_series.items():\n    if idx < len(counts):\n        counts[idx] = val\n\nweights = len(train_df) / (len(classes) * (counts + 1))\nclass_weights = torch.tensor(weights, dtype=torch.float).to(device)\n\nprint(f\"\\nFinal Dataset Sizes:\")\nprint(f\"Train: {len(train_df)} | Val: {len(val_df)} | Test: {len(test_df)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T20:09:07.622745Z","iopub.execute_input":"2025-12-01T20:09:07.623119Z","iopub.status.idle":"2025-12-01T20:09:08.297398Z","shell.execute_reply.started":"2025-12-01T20:09:07.623089Z","shell.execute_reply":"2025-12-01T20:09:08.296510Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.models as models\nimport torch.nn as nn\n\nclass SensorPreprocessor:\n    def __init__(self):\n        self.mean = None\n        self.std = None\n        \n    def fit(self, dataframe):\n        \"\"\" Calcula estat√≠sticas apenas no Treino \"\"\"\n        print(\"üßÆ Calculando estat√≠sticas globais (X, Y, Z)...\")\n        signals = dataframe[['accX', 'accY', 'accZ']].values\n        self.mean = np.mean(signals, axis=0)\n        self.std = np.std(signals, axis=0)\n        # Seguran√ßa contra divis√£o por zero\n        self.std[self.std == 0] = 1.0\n        print(f\"   M√©dia: {self.mean} | Std: {self.std}\")\n        \n    def transform(self, dataframe):\n        \"\"\" Normaliza e cria o 4¬∫ canal (Magnitude) \"\"\"\n        # 1. Pega os 3 canais originais\n        x = dataframe[['accX', 'accY', 'accZ']].values.astype(np.float32)\n        \n        # 2. Normaliza (Z-Score)\n        x_norm = (x - self.mean) / self.std\n        \n        # 3. Calcula Magnitude (Raiz da soma dos quadrados)\n        # Nota: Calculamos a magnitude sobre os dados normalizados para manter a escala\n        mag = np.sqrt(np.sum(x_norm**2, axis=1, keepdims=True))\n        \n        # 4. Concatena [X, Y, Z, Mag] -> Shape (N, 4)\n        x_final = np.concatenate([x_norm, mag], axis=1)\n        return x_final","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T20:09:08.299980Z","iopub.execute_input":"2025-12-01T20:09:08.300293Z","iopub.status.idle":"2025-12-01T20:09:08.306759Z","shell.execute_reply.started":"2025-12-01T20:09:08.300274Z","shell.execute_reply":"2025-12-01T20:09:08.306044Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class InMemoryCalfDataset(Dataset):\n    def __init__(self, dataframe, window_size=75, stride=None, mode='train', preprocessor=None):\n        self.window_size = window_size\n        self.indices = []\n        \n        print(f\"üî® Processando Dataset ({mode})...\")\n        \n        # 1. Aplica o Pr√©-processamento imediatamente (Economiza CPU no treino)\n        if preprocessor:\n            # Retorna array (N_samples, 4)\n            self.signals = preprocessor.transform(dataframe)\n        else:\n            raise ValueError(\"Voc√™ PRECISA passar um preprocessor treinado!\")\n\n        # 2. Labels e Segmentos\n        self.labels = dataframe['label_code'].values.astype('int64')\n        self.seg_ids = dataframe['segId'].values\n\n        # 3. Cria√ß√£o de Janelas (Slicing r√°pido com Numpy)\n        # Se treino, usa overlap (stride menor). Se teste, janela cheia.\n        if stride is None:\n            stride = window_size // 2 if mode == 'train' else window_size\n        \n        # Acha onde muda o segId para n√£o misturar bezerros/comportamentos\n        changes = np.where(self.seg_ids[:-1] != self.seg_ids[1:])[0] + 1\n        starts = np.concatenate(([0], changes))\n        ends = np.concatenate((changes, [len(self.signals)]))\n        \n        for start, end in zip(starts, ends):\n            n = end - start\n            if n >= window_size:\n                # Gera √≠ndices: [start, start+stride, start+2*stride...]\n                for i in range(start, end - window_size + 1, stride):\n                    self.indices.append(i)\n\n        print(f\"   ‚úÖ {len(self.indices)} janelas criadas.\")\n\n    def __len__(self): return len(self.indices)\n    \n    def __getitem__(self, idx):\n        start = self.indices[idx]\n        end = start + self.window_size\n        \n        # Slicing direto do array pr√©-processado\n        x = self.signals[start:end] # (75, 4)\n        y = self.labels[start]      # Label do in√≠cio da janela\n        \n        # PyTorch quer (Channels, Time) -> Permute para (4, 75)\n        return torch.tensor(x).permute(1, 0), torch.tensor(y, dtype=torch.long)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T20:09:08.308232Z","iopub.execute_input":"2025-12-01T20:09:08.308436Z","iopub.status.idle":"2025-12-01T20:09:08.322434Z","shell.execute_reply.started":"2025-12-01T20:09:08.308419Z","shell.execute_reply":"2025-12-01T20:09:08.321752Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torchvision.models as models\n\nclass ResNetBaseline(nn.Module):\n    def __init__(self, num_classes, in_channels=4):\n        super().__init__()\n        self.backbone = models.resnet18(weights=None)\n        self.backbone.conv1 = nn.Conv2d(\n            in_channels, 64, kernel_size=7, stride=2, padding=3, bias=False\n        )\n        n_features = self.backbone.fc.in_features\n        self.backbone.fc = nn.Linear(n_features, num_classes)\n\n    def forward(self, x):\n        x = x.unsqueeze(2) # (Batch, 4, 1, 75)\n        x = self.backbone(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T20:09:08.323021Z","iopub.execute_input":"2025-12-01T20:09:08.323242Z","iopub.status.idle":"2025-12-01T20:09:08.340036Z","shell.execute_reply.started":"2025-12-01T20:09:08.323209Z","shell.execute_reply":"2025-12-01T20:09:08.339427Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tqdm.notebook import tqdm\nimport copy\n\n# --- EARLY STOPPING CLASS ---\nclass EarlyStopping:\n    \"\"\"Stops training if validation loss does not improve for 'patience' epochs.\"\"\"\n    def __init__(self, patience, min_delta=0.001):\n        self.patience = patience\n        self.min_delta = min_delta\n        self.counter = 0\n        self.best_loss = float('inf')\n        self.early_stop = False\n        self.best_model_state = None\n\n    def __call__(self, val_loss, model):\n        if val_loss < self.best_loss - self.min_delta:\n            self.best_loss = val_loss\n            self.best_model_state = copy.deepcopy(model.state_dict())\n            self.counter = 0  # Reset counter\n        else:\n            self.counter += 1\n            #print(f'EarlyStopping count: {self.counter}/{self.patience}')\n            if self.counter >= self.patience:\n                self.early_stop = True\n\n\n\"\"\"\n# --- SETUP ---\nEPOCHS = 50\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n    optimizer, mode='min', factor=0.2, patience=10, verbose=True\n)\ncriterion = nn.CrossEntropyLoss(weight=class_weights)\n#early_stopper = EarlyStopping(patience=20)\n\nhistory = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n\nprint(\"Starting training...\")\n\n# ===========================\n# TRAINING LOOP\n# ===========================\nfor epoch in range(EPOCHS):\n    # --- Training Phase ---\n    model.train()\n    train_loss, correct, total = 0, 0, 0\n    \n    loop = tqdm(dl_train, desc=f\"Epoch {epoch+1}/{EPOCHS}\", leave=False)\n    for x, y in loop:\n        x, y = x.to(device), y.to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(x)\n        loss = criterion(outputs, y)\n        loss.backward()\n        optimizer.step()\n        \n        train_loss += loss.item()\n        _, predicted = outputs.max(1)\n        total += y.size(0)\n        correct += predicted.eq(y).sum().item()\n        loop.set_postfix(loss=loss.item())\n\n    avg_train_loss = train_loss / len(dl_train)\n    train_acc = 100 * correct / total\n\n    # --- Validation Phase ---\n    model.eval()\n    val_loss, correct, total = 0, 0, 0\n    with torch.no_grad():\n        for x, y in dl_val:\n            x, y = x.to(device), y.to(device)\n            outputs = model(x)\n            loss = criterion(outputs, y)\n            val_loss += loss.item()\n            _, predicted = outputs.max(1)\n            total += y.size(0)\n            correct += predicted.eq(y).sum().item()\n\n    avg_val_loss = val_loss / len(dl_val)\n    val_acc = 100 * correct / total\n\n    # Record history\n    history['train_loss'].append(avg_train_loss)\n    history['val_loss'].append(avg_val_loss)\n    history['train_acc'].append(train_acc)\n    history['val_acc'].append(val_acc)\n\n    if (epoch + 1) % 5 == 0:\n        print(f\"Epoch {epoch+1}: Train Loss={avg_train_loss:.4f} (Acc {train_acc:.1f}%) | \"\n              f\"Val Loss={avg_val_loss:.4f} (Acc {val_acc:.1f}%)\")\n    \n    scheduler.step(avg_val_loss)\n    #early_stopper(avg_val_loss, model)\n    \n    #if early_stopper.early_stop:\n    #    print(\"Early stopping triggered.\")\n    #    model.load_state_dict(early_stopper.best_model_state)\n    #    break\n\n\n# --- Plot Training History ---\nplt.figure(figsize=(14, 5))\n\n# Loss\nplt.subplot(1, 2, 1)\nplt.plot(history['train_loss'], label='Train Loss', marker='o')\nplt.plot(history['val_loss'], label='Validation Loss', marker='o')\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.title(\"Training and Validation Loss\")\nplt.legend()\nplt.grid(True, alpha=0.3)\n\n# Accuracy\nplt.subplot(1, 2, 2)\nplt.plot(history['train_acc'], label='Train Accuracy', marker='o')\nplt.plot(history['val_acc'], label='Validation Accuracy', marker='o')\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy (%)\")\nplt.title(\"Training and Validation Accuracy\")\nplt.legend()\nplt.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T20:09:08.340860Z","iopub.execute_input":"2025-12-01T20:09:08.341129Z","iopub.status.idle":"2025-12-01T20:09:08.357332Z","shell.execute_reply.started":"2025-12-01T20:09:08.341106Z","shell.execute_reply":"2025-12-01T20:09:08.356707Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport polars as pl\nimport numpy as np\nimport copy\nimport math\n\nclass TimeMAEConfig:\n    UNLABELED_PATH = '/kaggle/input/calf-dl/Time_Adj_Raw_Data.parquet'\n    \n    # Hiperpar√¢metros do Paper\n    FREQ = 25\n    WINDOW_SECONDS = 3.0\n    WINDOW_SIZE = int(FREQ * WINDOW_SECONDS) \n    PATCH_SIZE = 5   # Œ¥ (Delta do paper)\n    NUM_PATCHES = WINDOW_SIZE // PATCH_SIZE \n    \n    # Model Dimensions (Paper usa 64)\n    EMBED_DIM = 64   \n    NUM_HEADS = 4    \n    DROPOUT = 0.2    \n    \n    # Depth (Paper: 8 Encoder, 6 Decoder)\n    # Kaggle Safe: Vamos reduzir um pouco, mas manter a propor√ß√£o\n    DEPTH_ENC = 4 \n    DEPTH_DEC = 2\n    \n    # Masking & Tasks\n    MASK_RATIO = 0.60\n    CODEBOOK_SIZE = 128 # Vocabulary size\n    \n    # Optimization\n    BATCH_SIZE = 1024\n    LR = 0.003\n    WEIGHT_DECAY = 1e-4\n    MOMENTUM_TAU = 0.95\n    \n    # Loss Weights (Paper: alpha=1, beta search 1..10)\n    ALPHA = 1.0 # Peso MCC (Classifica√ß√£o)\n    BETA = 1.0  # Peso MRR (Regress√£o)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T20:09:08.358058Z","iopub.execute_input":"2025-12-01T20:09:08.358281Z","iopub.status.idle":"2025-12-01T20:09:08.374096Z","shell.execute_reply.started":"2025-12-01T20:09:08.358245Z","shell.execute_reply":"2025-12-01T20:09:08.373329Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Dataset e Collator (Reutilizando l√≥gica otimizada) ---\nclass UnlabeledMaedDataset(Dataset):\n    def __init__(self, parquet_path, window_size=75, stride=25):\n        # Stride=25 gera sobreposi√ß√£o para aumentar dados de treino (Data Augmentation natural)\n        df = pl.read_parquet(parquet_path)\n        self.signals = df.select(['accX', 'accY', 'accZ']).to_numpy().astype('float32')\n        self.window_size = window_size\n        self.indices = [i for i in range(0, len(self.signals) - window_size, stride)]\n        \n    def __len__(self): return len(self.indices)\n    def __getitem__(self, idx):\n        start = self.indices[idx]\n        window = self.signals[start : start + self.window_size]\n        # (3, 75)\n        return torch.from_numpy(window).permute(1, 0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T20:09:08.374951Z","iopub.execute_input":"2025-12-01T20:09:08.375210Z","iopub.status.idle":"2025-12-01T20:09:08.392964Z","shell.execute_reply.started":"2025-12-01T20:09:08.375193Z","shell.execute_reply":"2025-12-01T20:09:08.392301Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class MaskingCollator:\n    def __init__(self, num_patches, mask_ratio=0.60):\n        self.num_patches = num_patches\n        self.mask_ratio = mask_ratio\n        \n    def __call__(self, batch):\n        batch_x = torch.stack(batch) # (B, 3, 75)\n        B = batch_x.shape[0]\n        num_masked = int(self.mask_ratio * self.num_patches)\n        \n        # Cria m√°scara booleana (True = Mascarado)\n        mask = torch.zeros(B, self.num_patches, dtype=torch.bool)\n        for i in range(B):\n            rand_idx = torch.randperm(self.num_patches)[:num_masked]\n            mask[i, rand_idx] = True\n            \n        return batch_x, mask","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T20:09:08.393733Z","iopub.execute_input":"2025-12-01T20:09:08.393940Z","iopub.status.idle":"2025-12-01T20:09:08.407681Z","shell.execute_reply.started":"2025-12-01T20:09:08.393915Z","shell.execute_reply":"2025-12-01T20:09:08.407130Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Blocos Construtivos ---\nclass PatchEmbed(nn.Module):\n    \"\"\" Feature Encoder: Conv1d para Slicing \"\"\"\n    def __init__(self, in_ch=3, patch_size=5, embed_dim=64):\n        super().__init__()\n        self.proj = nn.Conv1d(in_ch, embed_dim, kernel_size=patch_size, stride=patch_size)\n    def forward(self, x):\n        # x: (B, 3, 75) -> (B, D, 15) -> (B, 15, D)\n        return self.proj(x).transpose(1, 2)\n\nclass CrossAttentionBlock(nn.Module):\n    \"\"\" Decoder Block (Cross-Attention) \"\"\"\n    def __init__(self, dim, num_heads, dropout=0.1):\n        super().__init__()\n        self.cross_attn = nn.MultiheadAttention(dim, num_heads, dropout=dropout, batch_first=True)\n        self.norm1 = nn.LayerNorm(dim)\n        self.ffn = nn.Sequential(\n            nn.Linear(dim, dim*4), nn.GELU(), nn.Dropout(dropout), nn.Linear(dim*4, dim)\n        )\n        self.norm2 = nn.LayerNorm(dim)\n        self.dropout = nn.Dropout(dropout)\n    \n    def forward(self, query, key_value):\n        attn_out, _ = self.cross_attn(query, key_value, key_value)\n        x = self.norm1(query + self.dropout(attn_out))\n        x = self.norm2(x + self.dropout(self.ffn(x)))\n        return x\n\nclass TimeMAE_Pretrain(nn.Module):\n    def __init__(self, cfg):\n        super().__init__()\n        self.cfg = cfg\n        \n        # --- COMPONENTES ONLINE (Theta & Phi) ---\n        # 1. Feature Encoder (CNN)\n        self.patch_embed = PatchEmbed(3, cfg.PATCH_SIZE, cfg.EMBED_DIM)\n        \n        # Positional Embeddings\n        self.pos_embed = nn.Parameter(torch.zeros(1, cfg.NUM_PATCHES, cfg.EMBED_DIM))\n        self.mask_token = nn.Parameter(torch.zeros(1, 1, cfg.EMBED_DIM))\n        nn.init.trunc_normal_(self.pos_embed, std=.02)\n        nn.init.normal_(self.mask_token, std=.02)\n        \n        # 2. Visible Encoder H_theta (Transformer)\n        enc_layer = nn.TransformerEncoderLayer(cfg.EMBED_DIM, cfg.NUM_HEADS, cfg.EMBED_DIM*4, cfg.DROPOUT, batch_first=True, norm_first=True)\n        self.visible_encoder = nn.TransformerEncoder(enc_layer, cfg.DEPTH_ENC)\n        \n        # 3. Decoupled Decoder F_phi (Cross-Attention)\n        self.decoupled_decoder = nn.ModuleList([\n            CrossAttentionBlock(cfg.EMBED_DIM, cfg.NUM_HEADS, cfg.DROPOUT) \n            for _ in range(cfg.DEPTH_DEC)\n        ])\n        \n        # --- COMPONENTES TARGET (Xi - C√≥pia do Encoder) ---\n        # O Target Encoder √© uma c√≥pia exata do Feature + Visible Encoder\n        self.target_patch_embed = copy.deepcopy(self.patch_embed)\n        self.target_visible_encoder = copy.deepcopy(self.visible_encoder)\n        \n        # Congelar Target Encoder (N√£o treina via backprop, s√≥ EMA)\n        for p in self.target_patch_embed.parameters(): p.requires_grad = False\n        for p in self.target_visible_encoder.parameters(): p.requires_grad = False\n        \n        # --- TOKENIZER (Codebook) ---\n        # Codebook C (K x D)\n        self.codebook = nn.Parameter(torch.randn(cfg.CODEBOOK_SIZE, cfg.EMBED_DIM))\n        # Prediction Heads leves (Inner Product)\n        # Cabe√ßa para predizer c√≥digo (MCC) e regress√£o (MRR) - Na verdade o output do decoder j√° √© D dimens√£o\n        \n    @torch.no_grad()\n    def update_target_encoder(self):\n        \"\"\" Atualiza pesos do Target via EMA (Eq. 6 do Paper) \"\"\"\n        m = self.cfg.MOMENTUM_TAU\n        for param_q, param_k in zip(self.patch_embed.parameters(), self.target_patch_embed.parameters()):\n            param_k.data = param_k.data * m + param_q.data * (1. - m)\n        for param_q, param_k in zip(self.visible_encoder.parameters(), self.target_visible_encoder.parameters()):\n            param_k.data = param_k.data * m + param_q.data * (1. - m)\n\n    def forward(self, x, mask):\n        \"\"\"\n        x: (B, 3, T)\n        mask: (B, N_patches) bool\n        \"\"\"\n        B = x.shape[0]\n        \n        # --- 1. ONLINE PATH (Vis√≠veis -> Decoder) ---\n        # Embed\n        x_patches = self.patch_embed(x) # (B, N, D)\n        x_patches = x_patches + self.pos_embed\n        \n        # Separar Vis√≠veis\n        # Nota: Simplificando indexa√ß√£o para o Kaggle (usando masked_select)\n        # Vis√≠veis: ~mask\n        visible_tokens = x_patches[~mask].view(B, -1, self.cfg.EMBED_DIM)\n        \n        # Encode Vis√≠veis H_theta\n        encoded_visible = self.visible_encoder(visible_tokens)\n        \n        # Preparar Queries para o Decoder (Posi√ß√µes Mascaradas)\n        # Queries = Mask Token + Pos Embed das posi√ß√µes mascaradas\n        pos_masked = self.pos_embed.expand(B, -1, -1)[mask].view(B, -1, self.cfg.EMBED_DIM)\n        decoder_queries = self.mask_token + pos_masked\n        \n        # Decode F_phi (Cross-Attention)\n        # Tenta reconstruir a representa√ß√£o latente\n        x_dec = decoder_queries\n        for layer in self.decoupled_decoder:\n            x_dec = layer(query=x_dec, key_value=encoded_visible)\n        \n        # x_dec agora √© F_phi(Z_tilde) -> Predi√ß√£o Latente (B, N_masked, D)\n        \n        # --- 2. TARGET PATH (Mascarados -> Ground Truth Latente) ---\n        with torch.no_grad():\n            target_patches = self.target_patch_embed(x) # Embed original\n            target_patches = target_patches + self.pos_embed # Add pos\n            \n            # Extrair apenas os mascarados para passar no Target Encoder\n            masked_real_tokens = target_patches[mask].view(B, -1, self.cfg.EMBED_DIM)\n            \n            # Encode Target H_xi\n            target_representations = self.target_visible_encoder(masked_real_tokens)\n            # Normaliza√ß√£o (LayerNorm impl√≠cito no transformer, mas bom garantir consist√™ncia)\n            target_representations = F.layer_norm(target_representations, target_representations.shape[-1:])\n            \n        return x_dec, target_representations\n    \n    def get_losses(self, pred_latents, target_latents):\n        \"\"\" Calcula MRR e MCC \"\"\"\n        # --- MRR Loss (Regression) ---\n        # L_align = || H_xi(Zm) - F_phi(Z_tilde) ||^2\n        loss_mrr = F.mse_loss(pred_latents, target_latents)\n        \n        flat_targets = target_latents.reshape(-1, self.cfg.EMBED_DIM)\n        flat_preds = pred_latents.reshape(-1, self.cfg.EMBED_DIM)\n        \n        # Calcular dist√¢ncias (Inner Product como no paper)\n        # Similarity = X @ C.T\n        with torch.no_grad():\n            # Criar labels discretos baseados na similaridade do Target com o Codebook\n            sim_target = torch.matmul(flat_targets, self.codebook.t()) # (N, K)\n            target_ids = torch.argmax(sim_target, dim=-1) # (N,) Labels discretos\n            \n        # 2. Predi√ß√£o (Inner product entre Predi√ß√£o e Codebook)\n        logits = torch.matmul(flat_preds, self.codebook.t()) # (N, K)\n        \n        loss_mcc = F.cross_entropy(logits, target_ids)\n        \n        return loss_mrr, loss_mcc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T20:09:08.408489Z","iopub.execute_input":"2025-12-01T20:09:08.408815Z","iopub.status.idle":"2025-12-01T20:09:08.427953Z","shell.execute_reply.started":"2025-12-01T20:09:08.408790Z","shell.execute_reply":"2025-12-01T20:09:08.427414Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cfg = TimeMAEConfig()\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = TimeMAE_Pretrain(cfg).to(device)\nds_ssl = UnlabeledMaedDataset(cfg.UNLABELED_PATH, window_size=cfg.WINDOW_SIZE, stride=25)\ndl_ssl = DataLoader(\n    ds_ssl, \n    batch_size=cfg.BATCH_SIZE, \n    shuffle=True, \n    num_workers=2, \n    pin_memory=True,\n    collate_fn=MaskingCollator(cfg.NUM_PATCHES, cfg.MASK_RATIO),\n    drop_last=True \n)\n\n\n\"\"\"\noptimizer = torch.optim.Adam(model.parameters(), lr=cfg.LR, weight_decay=cfg.WEIGHT_DECAY)\n\ncheckpoint_path = \"/kaggle/working/timemae_pretrained.pth\"\nstart_epoch = 0\nbest_loss = float('inf')\n\nif os.path.exists(checkpoint_path):\n    print(f\"üîÑ Checkpoint encontrado: {checkpoint_path}\")\n    try:\n        state = torch.load(checkpoint_path, map_location=device)\n        \n        if isinstance(state, dict) and 'model_state_dict' in state:\n            print(\"Detectado formato: Checkpoint Completo\")\n            model.load_state_dict(state['model_state_dict'])\n            \n            if 'optimizer_state_dict' in state:\n                optimizer.load_state_dict(state['optimizer_state_dict'])\n                print(\">> Otimizador restaurado.\")\n                \n            if 'loss' in state:\n                best_loss = state['loss']\n                \n        else:\n            print(\">> Detectado formato: Apenas Pesos (State Dict)\")\n            model.load_state_dict(state)\n        \n        print(\"Pesos carregados com sucesso! Continuando...\")\n        \n    except Exception as e:\n        print(f\"Erro ao carregar: {e}\")\n        print(\"Iniciando treino do ZERO para evitar inconsist√™ncias.\")\nelse:\n    print(\"Nenhum checkpoint encontrado. Iniciando treino do ZERO.\")\n\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n    optimizer, mode='min', factor=0.1, patience=3, verbose=True\n)\n\n# Training Loop\nEPOCHS = 10\nhistory = {'loss': [], 'mrr': [], 'mcc': []}\n\nprint(f\"üöÄ Iniciando Treino: Batch={cfg.BATCH_SIZE}, LR={cfg.LR}, Tau={cfg.MOMENTUM_TAU}\")\n\nmodel.train()\nfor epoch in range(EPOCHS):\n    total_loss = 0\n    total_mrr = 0\n    total_mcc = 0\n    \n    # Barra de progresso manual para n√£o poluir log\n    steps = len(dl_ssl)\n    \n    for batch_idx, (x, mask) in enumerate(dl_ssl):\n        x, mask = x.to(device), mask.to(device)\n        \n        optimizer.zero_grad()\n        \n        # Forward\n        pred_latents, target_latents = model(x, mask)\n        \n        # Loss\n        loss_mrr, loss_mcc = model.get_losses(pred_latents, target_latents)\n        loss = (cfg.ALPHA * loss_mcc) + (cfg.BETA * loss_mrr)\n        \n        loss.backward()\n        optimizer.step()\n        \n        # Momentum Update do Target Encoder\n        model.update_target_encoder()\n        \n        # Logs\n        total_loss += loss.item()\n        total_mrr += loss_mrr.item()\n        total_mcc += loss_mcc.item()\n        \n        # Print a cada 10% da √©poca\n        if batch_idx % (steps // 10) == 0 and batch_idx > 0:\n            print(f\"   Ep {epoch+1} [{batch_idx}/{steps}] Loss: {loss.item():.4f} (MRR: {loss_mrr.item():.4f})\")\n            \n    # Estat√≠sticas da √âpoca\n    avg_loss = total_loss / steps\n    avg_mrr = total_mrr / steps\n    avg_mcc = total_mcc / steps\n    history['loss'].append(avg_loss)\n    \n    # Atualiza Scheduler\n    current_lr = optimizer.param_groups[0]['lr']\n    print(f\"==> End Epoch {epoch+1} | Avg Loss: {avg_loss:.4f} | MRR: {avg_mrr:.4f} | LR: {current_lr}\")\n    \n    # Step do Scheduler (Reduz LR se estagnou)\n    scheduler.step(avg_loss)\n    \n    # --- Salvar Checkpoint (Salva sempre o melhor e o √∫ltimo) ---\n    save_dict = {\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict(),\n        'loss': avg_loss,\n    }\n    \n    # Salva o √∫ltimo estado (para resumir se cair)\n    torch.save(save_dict, \"timemae_last.pth\")\n    \n    # Salva o melhor modelo (para usar no fine-tuning)\n    if avg_loss < best_loss:\n        best_loss = avg_loss\n        torch.save(model.state_dict(), \"timemae_pretrained.pth\") # Salva s√≥ pesos p/ fine-tuning facilitar\n        print(f\"Novo melhor modelo salvo! (Loss: {best_loss:.4f})\")\n\nprint(\"Treinamento finalizado!\")\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T20:09:08.428681Z","iopub.execute_input":"2025-12-01T20:09:08.428908Z","iopub.status.idle":"2025-12-01T20:09:11.330638Z","shell.execute_reply.started":"2025-12-01T20:09:08.428885Z","shell.execute_reply":"2025-12-01T20:09:11.330039Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class TimeMAE_Classifier(nn.Module):\n    def __init__(self, cfg, num_classes):\n        super().__init__()\n        self.cfg = cfg\n        \n        # Backbone\n        self.patch_embed = PatchEmbed(3, cfg.PATCH_SIZE, cfg.EMBED_DIM)\n        self.pos_embed = nn.Parameter(torch.zeros(1, cfg.NUM_PATCHES, cfg.EMBED_DIM))\n        \n        # Encoder\n        enc_layer = nn.TransformerEncoderLayer(\n            d_model=cfg.EMBED_DIM, \n            nhead=cfg.NUM_HEADS, \n            dim_feedforward=cfg.EMBED_DIM*4, \n            dropout=cfg.DROPOUT, \n            batch_first=True, \n            norm_first=True\n        )\n        self.encoder = nn.TransformerEncoder(enc_layer, cfg.DEPTH_ENC)\n        \n        # Classification Head\n        self.norm = nn.LayerNorm(cfg.EMBED_DIM)\n        self.head = nn.Linear(cfg.EMBED_DIM, num_classes)\n        nn.init.trunc_normal_(self.pos_embed, std=.02)\n        \n    def forward(self, x):\n        # Embed & Pos\n        x = self.patch_embed(x) # (B, 15, D)\n        x = x + self.pos_embed  # Soma posi√ß√£o\n        \n        # 2. Encoder\n        x = self.encoder(x) \n        x = x.mean(dim=1)\n        \n        # 4. Classifica√ß√£o\n        x = self.norm(x)\n        logits = self.head(x)\n        return logits\n\n    def load_pretrained(self, path):\n        print(f\"Carregando pesos de: {path}\")\n        checkpoint = torch.load(path, map_location='cpu')\n        \n        model_dict = self.state_dict()\n        pretrained_dict = {}\n        \n        for k, v in checkpoint.items():\n            # Mapeia 'patch_embed' -> 'patch_embed'\n            if k.startswith('patch_embed') or k.startswith('pos_embed'):\n                pretrained_dict[k] = v\n                \n            # Mapeia 'visible_encoder' -> 'encoder'\n            elif k.startswith('visible_encoder'):\n                new_key = k.replace('visible_encoder', 'encoder')\n                pretrained_dict[new_key] = v\n                \n        # Filtra chaves que n√£o existem no modelo atual (Decoder, Target Encoder, etc.)\n        pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n        \n        # Carrega\n        missing, unexpected = self.load_state_dict(pretrained_dict, strict=False)\n        print(f\"Pesos carregados! (Ignorados: Decoder, TargetEnc)\")\n        print(f\"Camadas n√£o encontradas no checkpoint (Devem ser s√≥ a Head): {missing}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T20:09:11.331389Z","iopub.execute_input":"2025-12-01T20:09:11.331636Z","iopub.status.idle":"2025-12-01T20:09:11.381007Z","shell.execute_reply.started":"2025-12-01T20:09:11.331612Z","shell.execute_reply":"2025-12-01T20:09:11.380408Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Setup ---\nnum_classes = len(classes) # ~18\nmodel_ft = TimeMAE_Classifier(cfg, num_classes).to(device)\n\nimport os\nif os.path.exists(\"timemae_pretrained.pth\"):\n    model_ft.load_pretrained(\"timemae_pretrained.pth\")\nelse:\n    print(\"Aviso: Arquivo pr√©-treinado n√£o encontrado. Treinando do zero.\")\n\n# Dataloaders Supervisionados (Os mesmos que criamos pro Baseline)\ndl_train = DataLoader(ds_train, batch_size=256, shuffle=True, num_workers=2)\ndl_val = DataLoader(ds_val, batch_size=256, shuffle=False, num_workers=2)\n\n\"\"\"\n# Otimizador\noptimizer = torch.optim.Adam(model_ft.parameters(), lr=0.002, weight_decay=1e-3)\ncriterion = nn.CrossEntropyLoss(weight=class_weights) # Pesos das classes!\n\n# --- Loop de Treino ---\nprint(f\"\\nIniciando Fine-Tuning nas {num_classes} classes...\")\nEPOCHS = 200\n\nfor epoch in range(EPOCHS):\n    model_ft.train()\n    train_loss = 0\n    correct = 0\n    total = 0\n    \n    for x, y in dl_train:\n        x, y = x.to(device), y.to(device)\n        \n        optimizer.zero_grad()\n        logits = model_ft(x) # Forward sem m√°scara\n        loss = criterion(logits, y)\n        loss.backward()\n        optimizer.step()\n        \n        train_loss += loss.item()\n        _, predicted = logits.max(1)\n        total += y.size(0)\n        correct += predicted.eq(y).sum().item()\n        \n    # Valida√ß√£o\n    model_ft.eval()\n    val_loss = 0\n    val_correct = 0\n    val_total = 0\n    with torch.no_grad():\n        for x, y in dl_val:\n            x, y = x.to(device), y.to(device)\n            logits = model_ft(x)\n            loss = criterion(logits, y)\n            val_loss += loss.item()\n            _, predicted = logits.max(1)\n            val_total += y.size(0)\n            val_correct += predicted.eq(y).sum().item()\n            \n    # Logs\n    acc_train = 100 * correct / total\n    acc_val = 100 * val_correct / val_total\n    avg_train_loss = train_loss / len(dl_train)\n    avg_val_loss = val_loss / len(dl_val)\n\n    if (epoch + 1)  % 5 == 0:\n        print(f\"Ep {epoch+1}: Train Loss={avg_train_loss:.4f} (Acc {acc_train:.1f}%) | Val Loss={avg_val_loss:.4f} (Acc {acc_val:.1f}%)\")\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T20:09:11.381807Z","iopub.execute_input":"2025-12-01T20:09:11.382093Z","iopub.status.idle":"2025-12-01T20:09:11.409387Z","shell.execute_reply.started":"2025-12-01T20:09:11.382067Z","shell.execute_reply":"2025-12-01T20:09:11.408732Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ==============================================================================\n# 1. CLASSE DE AUGMENTATION (CORRIGIDA E ROBUSTA)\n# ==============================================================================\nclass TimeSeriesAugmentations:\n    def __init__(self, device):\n        self.device = device\n\n    def weak_aug(self, x):\n        \"\"\" \n        Fraca: Adiciona ru√≠do leve e muda escala. \n        \"\"\"\n        B, C, T = x.shape\n        sigma = 0.05\n        noise = torch.randn_like(x, device=self.device) * sigma     # Noise: Aditivo\n        scale = torch.rand(B, 1, 1, device=self.device) * 0.2 + 0.9 # Scale: Multiplicativo\n        return (x * scale) + noise\n\n    def strong_aug(self, x):\n        \"\"\" \n        Forte: Permuta√ß√£o de Segmentos + Time Masking.\n        \"\"\"\n        x = self.weak_aug(x) \n        \n        B, C, T = x.shape\n        x_aug = x.clone()\n        \n        # Permutation\n        if T > 10:\n            num_segs = np.random.randint(2, 5)\n            seg_len = T // num_segs\n            for i in range(B):\n                perm = torch.randperm(num_segs)\n                # Cria lista de fatias (slices)\n                segs = [x[i, :, p*seg_len : (p+1)*seg_len] for p in perm]\n                shuffled = torch.cat(segs, dim=1)\n                \n                # Ajuste de tamanho (padding ou crop se a divis√£o n√£o for exata)\n                curr_len = shuffled.shape[1]\n                if curr_len < T:\n                    pad = torch.zeros(C, T - curr_len, device=self.device)\n                    shuffled = torch.cat([shuffled, pad], dim=1)\n                elif curr_len > T:\n                    shuffled = shuffled[:, :T]\n                x_aug[i] = shuffled\n\n        # Time Masking \n        mask_ratio = 0.2\n        mask_len = int(T * mask_ratio)\n        for i in range(B):\n            start = np.random.randint(0, max(1, T - mask_len))\n            x_aug[i, :, start : start+mask_len] = 0.0\n            \n        return x_aug","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T20:09:11.410064Z","iopub.execute_input":"2025-12-01T20:09:11.410262Z","iopub.status.idle":"2025-12-01T20:09:11.418948Z","shell.execute_reply.started":"2025-12-01T20:09:11.410240Z","shell.execute_reply":"2025-12-01T20:09:11.418242Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ==============================================================================\n# 1. DATA AUGMENTATION\n# ==============================================================================\nclass TimeSeriesAugmentations:\n    def __init__(self, device):\n        self.device = device\n\n    def weak_aug(self, x):\n        \"\"\" Jittering (Ru√≠do) + Scaling (Escala) \"\"\"\n        B, C, T = x.shape\n        # Ru√≠do Gaussiano leve\n        noise = torch.randn_like(x, device=self.device) * 0.05\n        # Escala aleat√≥ria (0.8x a 1.2x) - Aumentei levemente o range para dificultar\n        scale = torch.rand(B, 1, 1, device=self.device) * 0.4 + 0.8 \n        return (x * scale) + noise\n\n    def strong_aug(self, x):\n        \"\"\" Permutation + Time Masking \"\"\"\n        x = self.weak_aug(x) # Aplica fraca primeiro\n        B, C, T = x.shape\n        x_aug = x.clone()\n        \n        # Permutation (Embaralha segmentos)\n        if T > 10:\n            num_segs = np.random.randint(2, 5)\n            seg_len = T // num_segs\n            for i in range(B):\n                perm = torch.randperm(num_segs)\n                # Slicing avan√ßado para evitar loops lentos em python puro se poss√≠vel\n                # Mas para manter legibilidade, mantemos a lista de slices\n                segs = [x[i, :, p*seg_len:(p+1)*seg_len] for p in perm]\n                shuffled = torch.cat(segs, dim=1)\n                \n                # Ajuste de tamanho\n                curr_len = shuffled.shape[1]\n                if curr_len < T:\n                    pad = torch.zeros(C, T - curr_len, device=self.device)\n                    shuffled = torch.cat([shuffled, pad], dim=1)\n                elif curr_len > T:\n                    shuffled = shuffled[:, :T]\n                x_aug[i] = shuffled\n\n        # Time Masking (Zera 30% da janela)\n        mask_len = int(T * 0.3)\n        for i in range(B):\n            start = np.random.randint(0, max(1, T - mask_len))\n            x_aug[i, :, start : start+mask_len] = 0.0\n            \n        return x_aug\n\n# ==============================================================================\n# 2. CONFIGURA√á√ïES & HIPERPAR√ÇMETROS\n# ==============================================================================\nCHECKPOINT_PATH = \"fixmatch_resnet.pth\"\nNUM_CLASSES = 19\nLR = 10        \nEPOCHS = 80\nFIXMATCH_THRESHOLD = 0.90 \nLAMBDA_U = 15.0          \n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Instancia Modelo (Garante 4 canais de entrada: X, Y, Z, Mag)\nmodel = ResNetBaseline(NUM_CLASSES, in_channels=4).to(device)\n\n# Weight Decay Agressivo (1e-3) para combater o Overfitting\noptimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=1e-3)\naugmenter = TimeSeriesAugmentations(device)\n\n# Scheduler: Se Val Loss n√£o cair por 3 √©pocas, reduz LR pela metade (Rea√ß√£o mais r√°pida)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n    optimizer, mode='min', factor=0.5, patience=3, verbose=True\n)\n\n# ==============================================================================\n# 3. L√ìGICA DE CHECKPOINT INTELIGENTE\n# ==============================================================================\nstart_epoch = 0\nbest_val_acc = 0.0\n\nif os.path.exists(CHECKPOINT_PATH):\n    print(f\"üîÑ Checkpoint encontrado: {CHECKPOINT_PATH}\")\n    try:\n        checkpoint = torch.load(CHECKPOINT_PATH, map_location=device)\n        model.load_state_dict(checkpoint['model_state_dict'])\n        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n        start_epoch = checkpoint['epoch'] + 1\n        best_val_acc = checkpoint.get('best_val_acc', 0.0)\n        print(f\"‚úÖ Retomando treino da √âpoca {start_epoch}. Recorde: {best_val_acc:.2f}%\")\n    except Exception as e:\n        print(f\"‚ö†Ô∏è Erro ao carregar checkpoint: {e}. Iniciando do zero.\")\nelse:\n    print(\"‚ú® Iniciando treino FixMatch do ZERO.\")\n\n# Iterador infinito para Unlabeled Data\ndef cycle(iterable):\n    while True:\n        for x in iterable:\n            yield x\nunlabeled_iter = cycle(dl_ssl)\n\n# Preparar tensores de normaliza√ß√£o na GPU (Evita transfer√™ncias repetidas)\nif preprocessor.mean is None: raise ValueError(\"Preprocessor n√£o treinado!\")\nmean_gpu = torch.tensor(preprocessor.mean, device=device, dtype=torch.float32).view(1, 3, 1)\nstd_gpu = torch.tensor(preprocessor.std, device=device, dtype=torch.float32).view(1, 3, 1)\n\n# ==============================================================================\n# 4. LOOP DE TREINAMENTO (SUPER TUNADO)\n# ==============================================================================\nprint(f\"üöÄ Rodando FixMatch (Theta={FIXMATCH_THRESHOLD}, Lambda={LAMBDA_U}) por {EPOCHS} √©pocas...\")\n\nfor epoch in range(start_epoch, EPOCHS):\n    model.train()\n    \n    # M√©tricas Acumuladas\n    train_loss_acc = 0\n    sup_loss_acc = 0\n    unsup_loss_acc = 0\n    mask_count = 0\n    total_unlabeled = 0\n    \n    # Acur√°cia de Treino (Novo!)\n    train_correct = 0\n    train_total = 0\n    \n    for batch_idx, (inputs_x, targets_x) in enumerate(dl_train):\n        # 1. Dados Rotulados (Labeled)\n        inputs_x, targets_x = inputs_x.to(device), targets_x.to(device)\n        \n        # 2. Dados N√£o Rotulados (Unlabeled) - Tratamento de Erros de Iterador\n        try:\n            batch_u = next(unlabeled_iter)\n            inputs_u_raw = batch_u[0] if isinstance(batch_u, (list, tuple)) else batch_u\n        except:\n            # Reinicia se necess√°rio (raro)\n            unlabeled_iter = cycle(dl_ssl)\n            inputs_u_raw = next(unlabeled_iter)[0]\n            \n        inputs_u_raw = inputs_u_raw.to(device)\n        \n        # --- ADAPTA√á√ÉO ON-THE-FLY (3 -> 4 Canais) ---\n        with torch.no_grad():\n            u_norm = (inputs_u_raw - mean_gpu) / std_gpu\n            u_mag = torch.sqrt(torch.sum(u_norm**2, dim=1, keepdim=True))\n            inputs_u = torch.cat([u_norm, u_mag], dim=1)\n            \n        total_unlabeled += inputs_u.size(0)\n        \n        # --- A. SUPERVISIONADO ---\n        # Weak Aug no Labeled para evitar memoriza√ß√£o (Regulariza√ß√£o)\n        inputs_x_aug = augmenter.weak_aug(inputs_x)\n        logits_x = model(inputs_x_aug)\n        loss_sup = nn.CrossEntropyLoss(weight=class_weights)(logits_x, targets_x)\n        \n        # C√°lculo de Acur√°cia de Treino\n        with torch.no_grad():\n            _, pred_x = logits_x.max(1)\n            train_correct += pred_x.eq(targets_x).sum().item()\n            train_total += inputs_x.size(0)\n        \n        # --- B. N√ÉO SUPERVISIONADO (FIXMATCH) ---\n        with torch.no_grad():\n            # Weak Aug -> Pseudo-Label\n            inputs_u_weak = augmenter.weak_aug(inputs_u)\n            logits_u_weak = model(inputs_u_weak)\n            probs_u = torch.softmax(logits_u_weak, dim=1)\n            max_probs, pseudo_label = torch.max(probs_u, dim=1)\n            \n            # M√°scara de Confian√ßa\n            mask = max_probs.ge(FIXMATCH_THRESHOLD).float()\n            mask_count += mask.sum().item()\n\n        # Strong Aug -> Predi√ß√£o (Gradiente ativado aqui!)\n        inputs_u_strong = augmenter.strong_aug(inputs_u)\n        logits_u_strong = model(inputs_u_strong)\n        \n        loss_u_unreduced = nn.CrossEntropyLoss(reduction='none')(logits_u_strong, pseudo_label)\n        loss_unsup = (loss_u_unreduced * mask).mean()\n        \n        # --- OTIMIZA√á√ÉO ---\n        loss = loss_sup + (LAMBDA_U * loss_unsup)\n        \n        optimizer.zero_grad(set_to_none=True) # Otimiza√ß√£o de mem√≥ria\n        loss.backward()\n        \n        # Gradient Clipping (Estabilidade para LRs altos)\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        \n        optimizer.step()\n        \n        # Logs\n        train_loss_acc += loss.item()\n        sup_loss_acc += loss_sup.item()\n        unsup_loss_acc += loss_unsup.item()\n        \n    # --- M√âDIAS DA √âPOCA ---\n    avg_train_loss = train_loss_acc / len(dl_train)\n    avg_sup = sup_loss_acc / len(dl_train)\n    avg_unsup_weighted = (unsup_loss_acc / len(dl_train)) * LAMBDA_U\n    mask_rate = mask_count / max(total_unlabeled, 1)\n    train_acc = 100. * train_correct / train_total\n    \n    # --- VALIDA√á√ÉO ---\n    model.eval()\n    val_loss = 0\n    correct = 0\n    total = 0\n    \n    with torch.no_grad():\n        for x, y in dl_val:\n            x, y = x.to(device), y.to(device)\n            logits = model(x)\n            loss = nn.CrossEntropyLoss(weight=class_weights)(logits, y)\n            \n            val_loss += loss.item()\n            _, predicted = logits.max(1)\n            total += y.size(0)\n            correct += predicted.eq(y).sum().item()\n            \n    avg_val_loss = val_loss / len(dl_val)\n    val_acc = 100. * correct / total\n    \n    scheduler.step(avg_val_loss)\n    \n    # Print Informativo\n    print(f\"Ep {epoch+1}/{EPOCHS} | Train Loss: {avg_train_loss:.3f} [Sup: {avg_sup:.3f}, Unsup: {avg_unsup_weighted:.3f}]\")\n    print(f\"   >>> Train Acc: {train_acc:.2f}% | Mask Rate: {mask_rate:.1%}\")\n    print(f\"   >>> Val Loss:  {avg_val_loss:.4f} | Val Acc:   {val_acc:.2f}%\")\n    \n    # --- CHECKPOINT ---\n    # Salva o melhor modelo (baseado na Val Acc)\n    if val_acc > best_val_acc:\n        best_val_acc = val_acc\n        print(f\"üíæ Novo Recorde! ({best_val_acc:.2f}%)\")\n        torch.save({\n            'epoch': epoch,\n            'model_state_dict': model.state_dict(),\n            'best_val_acc': best_val_acc,\n            'optimizer_state_dict': optimizer.state_dict(),\n            'scheduler_state_dict': scheduler.state_dict(),\n        }, CHECKPOINT_PATH)\n        \n    # Salva snapshot a cada 5 √©pocas\n    if (epoch + 1) % 5 == 0:\n        torch.save(model.state_dict(), f\"fixmatch_ep{epoch+1}.pth\")\n\nprint(\"‚úÖ Treinamento Finalizado.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T23:43:02.835639Z","iopub.execute_input":"2025-12-01T23:43:02.835943Z","iopub.status.idle":"2025-12-02T00:26:28.795112Z","shell.execute_reply.started":"2025-12-01T23:43:02.835916Z","shell.execute_reply":"2025-12-02T00:26:28.794189Z"}},"outputs":[],"execution_count":null}]}